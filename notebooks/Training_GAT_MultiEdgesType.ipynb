{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10013909,"sourceType":"datasetVersion","datasetId":6165206},{"sourceId":10063026,"sourceType":"datasetVersion","datasetId":6201470},{"sourceId":10063457,"sourceType":"datasetVersion","datasetId":6201771},{"sourceId":10127056,"sourceType":"datasetVersion","datasetId":6064823},{"sourceId":211484469,"sourceType":"kernelVersion"},{"sourceId":192231,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":163892,"modelId":186242}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall torch torchvision torchaudio -y\n!pip install torch==2.0.0+cu118 torchvision==0.15.0+cu118 torchaudio==2.0.0 -f https://download.pytorch.org/whl/torch_stable.html\n!pip install torch_geometric\n!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import nn, optim, Tensor\nfrom torch_sparse import SparseTensor, matmul\nimport torch_geometric\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.data import HeteroData\nfrom torch_geometric.utils import negative_sampling\nfrom torch_geometric.transforms import ToUndirected\nfrom torch_geometric.loader import LinkNeighborLoader\nfrom torch_geometric.nn import GATConv, to_hetero\nfrom tqdm import tqdm\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-08T02:33:12.882105Z","iopub.execute_input":"2024-12-08T02:33:12.882409Z","iopub.status.idle":"2024-12-08T02:35:35.922983Z","shell.execute_reply.started":"2024-12-08T02:33:12.882380Z","shell.execute_reply":"2024-12-08T02:35:35.921864Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nFound existing installation: torchvision 0.19.0\nUninstalling torchvision-0.19.0:\n  Successfully uninstalled torchvision-0.19.0\nFound existing installation: torchaudio 2.4.0\nUninstalling torchaudio-2.4.0:\n  Successfully uninstalled torchaudio-2.4.0\nLooking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch==2.0.0+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m515.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.15.0+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.0.0\n  Downloading https://download.pytorch.org/whl/rocm5.4.2/torchaudio-2.0.0%2Brocm5.4.2-cp310-cp310-linux_x86_64.whl (4.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.1.4)\nCollecting triton==2.0.0 (from torch==2.0.0+cu118)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0+cu118) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0+cu118) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0+cu118) (10.3.0)\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\nCollecting torchaudio==2.0.0\n  Downloading https://download.pytorch.org/whl/rocm5.3/torchaudio-2.0.0%2Brocm5.3-cp310-cp310-linux_x86_64.whl (4.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting cmake (from triton==2.0.0->torch==2.0.0+cu118)\n  Downloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nCollecting lit (from triton==2.0.0->torch==2.0.0+cu118)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0+cu118) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0+cu118) (1.3.0)\nDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lit, cmake, triton, torch, torchvision, torchaudio\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.31.1 lit-18.1.8 torch-2.0.0+cu118 torchaudio-2.0.0+cu118 torchvision-0.15.0+cu118 triton-2.0.0\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.6.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.6.2)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\nLooking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\nCollecting pyg_lib\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.4.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torch_cluster\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torch_spline_conv\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.6/886.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_sparse) (1.14.1)\nRequirement already satisfied: numpy<2.3,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch_sparse) (1.26.4)\nInstalling collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\nSuccessfully installed pyg_lib-0.4.0+pt20cu118 torch_cluster-1.6.3+pt20cu118 torch_scatter-2.1.2+pt20cu118 torch_sparse-0.6.18+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n/kaggle/input/mooccubex-hgat/__results__.html\n/kaggle/input/mooccubex-hgat/__notebook__.ipynb\n/kaggle/input/mooccubex-hgat/__output__.json\n/kaggle/input/mooccubex-hgat/custom.css\n/kaggle/input/mooccubex/course_map.csv\n/kaggle/input/mooccubex/val_df.csv\n/kaggle/input/mooccubex/course_prepared.json\n/kaggle/input/mooccubex/mapped_n_core_user_course.csv\n/kaggle/input/mooccubex/mapped_course-school.csv\n/kaggle/input/mooccubex/mapped_course-field.csv\n/kaggle/input/mooccubex/mapped_course-teacher.csv\n/kaggle/input/mooccubex/train_df.csv\n/kaggle/input/mooccubex/test_df.csv\n/kaggle/input/kg-final/kg_final.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data_path = '/kaggle/input/mooccubex/train_df.csv' # Data path\ndf = pd.read_csv(data_path)\n\n# Convert course interact string from feature column to list\ndef str_to_list(x): # Function to split user's course interact list from string.\n    return x[1:-1].split(',')\n\ndf['feature'] = df['feature'].apply(str_to_list) # Apply str_to_list to course interact string.\ndf['feature'] = df['feature'].apply(lambda x: [int(i) for i in x]) # Convert every course type to int.\n\n# Drop column feature_time.\ndf = df.drop(columns=['feature_time'])\n\n# Explode df with feature column.\nexploded_df = df.explode('feature')\nexploded_df.reset_index(drop=True)\nexploded_df['feature'] = exploded_df['feature'].astype('int64')\n\n# Extract columns\nuser_col = torch.tensor(exploded_df['user'].values, dtype=torch.int64)\ncourse_col = torch.tensor(exploded_df['feature'].values, dtype=torch.int64)\n\ntrain_edge_index = torch.stack([user_col, course_col], dim=0)\n\n# Update num_users and num_courses\nnum_users = user_col.max().item() + 1\nnum_courses = course_col.max().item() + 1\n\n# Shift course indices and create SparseTensor\ntrain_sparse_edge_index = SparseTensor(\n    row = user_col,\n    col = course_col + num_users,\n    sparse_sizes=(num_users + num_courses, num_users + num_courses)\n)\n\nprint(train_sparse_edge_index)\n\ndata_path = '/kaggle/input/mooccubex/val_df.csv'\ndf = pd.read_csv(data_path)\ndf = df[df['val_label'] < num_courses]\n\ntest_user_col = torch.tensor(df['user'].values, dtype=torch.int64)\ntest_course_col = torch.tensor(df['val_label'].values, dtype=torch.int64)\n\ntest_edge_index = torch.stack([test_user_col, test_course_col], dim=0)\n\ntest_course_col_shifted = test_course_col + num_users\ntest_sparse_edge_index = SparseTensor(\n    row=test_user_col,\n    col=test_course_col_shifted,\n    sparse_sizes=(num_users + num_courses, num_users + num_courses)\n)\n\nprint(test_sparse_edge_index)\n\n# Load course - school data: Course - school interact\ndata_path = '/kaggle/input/mooccubex/mapped_course-school.csv' # Data path\ndf = pd.read_csv(data_path) # Read data\ndf = df[df['school'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - school relastionships.\nschool_mapping = {school: idx for idx, school in enumerate(df['school'].unique())}\ndf['school'] = df['school'].map(school_mapping)\n\n# Prepare course - school edge index\ncourse_col = torch.tensor(df['course'].values, dtype=torch.int64)\nschool_col = torch.tensor(df['school'].values, dtype=torch.int64)\ncourse_school_edge_index = torch.stack([course_col, school_col], dim=0) # Create course - school edge index\nnum_schools = len(school_mapping)\n\ncourse_school_sparse_edge_index = SparseTensor(\n    row = school_col + num_users + num_courses,\n    col = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_schools, num_users + num_courses + num_schools)\n)\n\nprint(course_school_sparse_edge_index)\n\n# Load course - teacher data: Course - teacher interact\ndata_path = '/kaggle/input/mooccubex/mapped_course-teacher.csv' # Data path\ndf = pd.read_csv(data_path) # Read data\ndf = df[df['id'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - teacher relastionships.\nteacher_mapping = {teacher: idx for idx, teacher in enumerate(df['teachers'].unique())}\ndf['teachers'] = df['teachers'].map(teacher_mapping)\n\n# Prepare course - teacher edge index\ncourse_col = torch.tensor(df['id'].values, dtype=torch.int64)\nteacher_col = torch.tensor(df['teachers'].values, dtype=torch.int64)\ncourse_teacher_edge_index = torch.stack([course_col, teacher_col], dim=0) # Create course - teacher edge index\nnum_teachers = len(teacher_mapping)\n\ncourse_teacher_sparse_edge_index = SparseTensor(\n    row = teacher_col + num_users + num_courses + num_schools,\n    col = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_schools + num_teachers, num_users + num_courses + num_schools + num_teachers)\n)\n\nprint(course_teacher_sparse_edge_index)\n\n# Load course - field data: Course - field interact\ndata_path = '/kaggle/input/mooccubex/mapped_course-field.csv' # Data path\ndf = pd.read_csv(data_path) # Read data\ndf = df[df['id'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - field relastionships.\nfield_mapping = {field: idx for idx, field in enumerate(df['field'].unique())}\ndf['field'] = df['field'].map(field_mapping)\n\n# Prepare course - field edge index\ncourse_col = torch.tensor(df['id'].values, dtype=torch.int64)\nfield_col = torch.tensor(df['field'].values, dtype=torch.int64)\ncourse_field_edge_index = torch.stack([course_col, field_col], dim=0) # Create course - field edge index\nnum_fields = len(field_mapping)\n\ncourse_field_sparse_edge_index = SparseTensor(\n    col = field_col + num_users + num_courses + num_schools + num_teachers,\n    row = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_schools + num_teachers + num_fields, num_users + num_courses + num_schools + num_teachers + num_fields)\n)\n\nprint(course_field_sparse_edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:35:35.925018Z","iopub.execute_input":"2024-12-08T02:35:35.925462Z","iopub.status.idle":"2024-12-08T02:35:38.728986Z","shell.execute_reply.started":"2024-12-08T02:35:35.925433Z","shell.execute_reply":"2024-12-08T02:35:38.728031Z"}},"outputs":[{"name":"stdout","text":"SparseTensor(row=tensor([    0,     0,     0,  ..., 99969, 99969, 99969]),\n             col=tensor([ 99970,  99971,  99972,  ..., 100235, 100410, 101954]),\n             size=(102797, 102797), nnz=1796450, density=0.02%)\nSparseTensor(row=tensor([    0,     1,     2,  ..., 99967, 99968, 99969]),\n             col=tensor([ 99973,  99971,  99975,  ..., 102158, 102045, 101687]),\n             size=(102797, 102797), nnz=99970, density=0.00%)\nSparseTensor(row=tensor([102797, 102797, 102797,  ..., 103218, 103219, 103220]),\n             col=tensor([ 99971,  99972,  99973,  ..., 101245, 101256, 101696]),\n             size=(103221, 103221), nnz=2850, density=0.00%)\nSparseTensor(row=tensor([103221, 103221, 103221,  ..., 112171, 112172, 112173]),\n             col=tensor([100216, 100318, 100603,  ..., 102608, 102608, 101696]),\n             size=(112174, 112174), nnz=10651, density=0.00%)\nSparseTensor(row=tensor([ 99972,  99973,  99979,  99979,  99981,  99982,  99982,  99984,  99986,\n                            99987,  99988,  99991,  99999, 100004, 100010, 100014, 100016, 100017,\n                           100019, 100020, 100020, 100022, 100026, 100036, 100036, 100042, 100044,\n                           100044, 100051, 100052, 100055, 100061, 100066, 100066, 100067, 100067,\n                           100068, 100068, 100068, 100071, 100074, 100077, 100083, 100092, 100094,\n                           100095, 100096, 100098, 100099, 100099, 100099, 100109, 100112, 100115,\n                           100116, 100118, 100119, 100119, 100121, 100129, 100130, 100131, 100132,\n                           100134, 100138, 100143, 100152, 100160, 100161, 100163, 100164, 100164,\n                           100165, 100165, 100166, 100167, 100168, 100171, 100172, 100172, 100173,\n                           100174, 100174, 100175, 100180, 100180, 100180, 100180, 100180, 100180,\n                           100180, 100185, 100190, 100191, 100194, 100197, 100204, 100210, 100217,\n                           100222, 100222, 100223, 100225, 100230, 100236, 100238, 100259, 100259,\n                           100259, 100272, 100278, 100279, 100279, 100283, 100284, 100284, 100288,\n                           100291, 100293, 100299, 100301, 100302, 100305, 100308, 100324, 100324,\n                           100328, 100331, 100332, 100335, 100336, 100337, 100338, 100339, 100343,\n                           100345, 100348, 100349, 100351, 100353, 100354, 100361, 100372, 100372,\n                           100373, 100391, 100392, 100395, 100395, 100395, 100395, 100396, 100397,\n                           100399, 100399, 100400, 100400, 100401, 100403, 100406, 100406, 100407,\n                           100407, 100409, 100412, 100412, 100415, 100415, 100418, 100419, 100423,\n                           100425, 100426, 100427, 100430, 100449, 100450, 100452, 100454, 100458,\n                           100459, 100459, 100462, 100478, 100479, 100480, 100481, 100483, 100491,\n                           100492, 100493, 100502, 100504, 100520, 100520, 100523, 100532, 100534,\n                           100534, 100534, 100535, 100536, 100540, 100541, 100542, 100550, 100550,\n                           100551, 100551, 100557, 100557, 100561, 100562, 100563, 100564, 100566,\n                           100567, 100567, 100574, 100575, 100580, 100582, 100582, 100585, 100601,\n                           100604, 100606, 100606, 100610, 100612, 100622, 100627, 100627, 100628,\n                           100630, 100631, 100631, 100632, 100636, 100636, 100641, 100642, 100642,\n                           100642, 100645, 100655, 100658, 100660, 100667, 100670, 100670, 100672,\n                           100675, 100675, 100677, 100683, 100684, 100686, 100686, 100686, 100687,\n                           100688, 100688, 100688, 100703, 100703, 100704, 100707, 100712, 100716,\n                           100717, 100720, 100720, 100721, 100722, 100722, 100724, 100729, 100732,\n                           100733, 100737, 100740, 100745, 100755, 100756, 100756, 100759, 100761,\n                           100761, 100762, 100767, 100767, 100773, 100776, 100779, 100780, 100780,\n                           100782, 100786, 100789, 100792, 100802, 100810, 100813, 100813, 100813,\n                           100814, 100822, 100822, 100823, 100831, 100831, 100831, 100832, 100836,\n                           100865, 100869, 100869, 100909, 100910, 100916, 100917, 100919, 100925,\n                           100935, 100935, 100937, 100938, 100938, 100944, 100951, 100954, 100956,\n                           100959, 100959, 100960, 100965, 100967, 100974, 100983, 100984, 101031,\n                           101036, 101048, 101053, 101053, 101053, 101055, 101074, 101075, 101085,\n                           101086, 101087, 101091, 101103, 101140, 101141, 101141, 101144, 101147,\n                           101152, 101152, 101153, 101153, 101155, 101200, 101209, 101240, 101240,\n                           101248, 101248, 101253, 101265, 101265, 101268, 101269, 101269, 101270,\n                           101279, 101281, 101300, 101300, 101319, 101331, 101332, 101332, 101353,\n                           101355, 101355, 101358, 101368, 101368, 101368, 101370, 101370, 101371,\n                           101372, 101376, 101385, 101388, 101389, 101391, 101399, 101402, 101410,\n                           101415, 101415, 101416, 101416, 101419, 101421, 101425, 101426, 101428,\n                           101428, 101440, 101442, 101443, 101443, 101446, 101457, 101467, 101468,\n                           101482, 101483, 101484, 101484, 101485, 101486, 101488, 101489, 101494,\n                           101494, 101502, 101503, 101504, 101504, 101506, 101507, 101532, 101533,\n                           101537, 101540, 101542, 101542, 101547, 101550, 101559, 101559, 101561,\n                           101562, 101563, 101568, 101590, 101592, 101596, 101597, 101597, 101613,\n                           101617, 101617, 101639, 101639, 101646, 101646, 101649, 101657, 101658,\n                           101659, 101670, 101671, 101673, 101676, 101676, 101680, 101697, 101699,\n                           101703, 101707, 101707, 101708, 101715, 101717, 101731, 101741, 101745,\n                           101745, 101746, 101746, 101748, 101752, 101759, 101841, 101865, 101866,\n                           101884, 101885, 101888, 101890, 101890, 101890, 101899, 101901, 101909,\n                           101922, 101944, 101955, 101957, 101967, 101969, 101982, 101990, 101998,\n                           102000, 102006, 102022, 102029, 102030, 102053, 102082, 102091, 102094,\n                           102104, 102148, 102151, 102155, 102160, 102168, 102176, 102178, 102191,\n                           102191, 102197, 102233, 102233, 102265, 102268, 102272, 102299, 102346,\n                           102351, 102371, 102387, 102435, 102446, 102446, 102490, 102490, 102535,\n                           102546, 102645, 102667, 102689, 102747, 102747, 102782]),\n             col=tensor([112193, 112182, 112175, 112215, 112193, 112218, 112247, 112226, 112243,\n                           112195, 112185, 112175, 112199, 112197, 112213, 112211, 112195, 112190,\n                           112181, 112176, 112198, 112185, 112176, 112218, 112220, 112226, 112184,\n                           112197, 112177, 112197, 112231, 112213, 112185, 112190, 112178, 112234,\n                           112182, 112183, 112184, 112180, 112193, 112226, 112193, 112226, 112176,\n                           112221, 112199, 112193, 112193, 112208, 112212, 112176, 112185, 112239,\n                           112195, 112193, 112197, 112204, 112183, 112196, 112201, 112196, 112199,\n                           112219, 112193, 112211, 112195, 112195, 112199, 112185, 112175, 112195,\n                           112184, 112195, 112226, 112226, 112226, 112195, 112206, 112226, 112239,\n                           112203, 112209, 112239, 112183, 112186, 112187, 112235, 112236, 112237,\n                           112238, 112193, 112222, 112222, 112211, 112190, 112175, 112180, 112176,\n                           112175, 112176, 112176, 112176, 112180, 112209, 112226, 112182, 112183,\n                           112184, 112176, 112181, 112210, 112216, 112177, 112175, 112195, 112199,\n                           112206, 112181, 112176, 112220, 112193, 112219, 112204, 112188, 112190,\n                           112196, 112176, 112176, 112176, 112175, 112177, 112177, 112176, 112195,\n                           112198, 112200, 112205, 112190, 112176, 112211, 112193, 112177, 112190,\n                           112175, 112204, 112204, 112178, 112194, 112224, 112230, 112177, 112222,\n                           112176, 112202, 112191, 112206, 112202, 112240, 112197, 112204, 112197,\n                           112204, 112180, 112175, 112179, 112181, 112188, 112181, 112197, 112206,\n                           112203, 112206, 112206, 112240, 112193, 112193, 112193, 112193, 112193,\n                           112182, 112184, 112195, 112180, 112193, 112193, 112193, 112226, 112193,\n                           112208, 112208, 112193, 112226, 112177, 112185, 112198, 112181, 112191,\n                           112208, 112212, 112226, 112226, 112206, 112224, 112224, 112244, 112246,\n                           112244, 112246, 112180, 112210, 112193, 112193, 112193, 112226, 112184,\n                           112209, 112216, 112193, 112193, 112193, 112196, 112201, 112201, 112174,\n                           112175, 112191, 112212, 112193, 112195, 112208, 112207, 112208, 112215,\n                           112190, 112203, 112218, 112218, 112186, 112187, 112217, 112224, 112232,\n                           112233, 112226, 112195, 112188, 112226, 112209, 112243, 112246, 112241,\n                           112243, 112244, 112210, 112175, 112200, 112218, 112224, 112247, 112175,\n                           112190, 112193, 112201, 112180, 112193, 112180, 112206, 112177, 112209,\n                           112192, 112185, 112195, 112180, 112189, 112194, 112248, 112211, 112240,\n                           112211, 112244, 112192, 112217, 112195, 112209, 112216, 112209, 112184,\n                           112197, 112185, 112243, 112246, 112177, 112181, 112198, 112185, 112195,\n                           112232, 112178, 112217, 112198, 112193, 112191, 112203, 112218, 112239,\n                           112204, 112175, 112179, 112247, 112203, 112218, 112239, 112208, 112212,\n                           112234, 112182, 112184, 112201, 112199, 112197, 112224, 112199, 112219,\n                           112181, 112243, 112244, 112201, 112211, 112197, 112246, 112180, 112193,\n                           112196, 112201, 112248, 112209, 112195, 112243, 112195, 112195, 112208,\n                           112241, 112202, 112243, 112249, 112250, 112188, 112247, 112176, 112176,\n                           112247, 112200, 112226, 112212, 112218, 112224, 112243, 112217, 112176,\n                           112243, 112244, 112243, 112244, 112179, 112206, 112195, 112189, 112223,\n                           112208, 112227, 112207, 112243, 112244, 112181, 112180, 112211, 112246,\n                           112182, 112193, 112179, 112190, 112180, 112176, 112204, 112211, 112211,\n                           112176, 112227, 112176, 112181, 112190, 112201, 112204, 112211, 112193,\n                           112193, 112193, 112176, 112195, 112176, 112195, 112189, 112213, 112177,\n                           112202, 112212, 112202, 112212, 112203, 112189, 112207, 112207, 112207,\n                           112213, 112214, 112214, 112189, 112231, 112197, 112227, 112199, 112176,\n                           112221, 112240, 112218, 112251, 112206, 112193, 112203, 112206, 112243,\n                           112244, 112176, 112206, 112178, 112222, 112224, 112224, 112201, 112243,\n                           112189, 112193, 112206, 112239, 112218, 112185, 112228, 112229, 112176,\n                           112195, 112193, 112188, 112196, 112176, 112244, 112218, 112220, 112195,\n                           112193, 112207, 112185, 112193, 112184, 112197, 112175, 112175, 112178,\n                           112188, 112224, 112199, 112184, 112175, 112179, 112211, 112193, 112220,\n                           112199, 112193, 112205, 112193, 112186, 112189, 112176, 112206, 112206,\n                           112218, 112206, 112218, 112195, 112201, 112187, 112199, 112180, 112193,\n                           112213, 112208, 112189, 112189, 112211, 112242, 112197, 112193, 112176,\n                           112246, 112219, 112201, 112175, 112197, 112180, 112192, 112195, 112223,\n                           112200, 112243, 112191, 112245, 112245, 112212, 112193, 112184, 112215,\n                           112179, 112207, 112206, 112226, 112221, 112211, 112192, 112224, 112209,\n                           112216, 112234, 112184, 112197, 112208, 112217, 112225, 112224, 112243,\n                           112197, 112181, 112181, 112214, 112182, 112184, 112189, 112222, 112217,\n                           112217, 112180, 112246, 112193, 112214, 112231, 112196]),\n             size=(112252, 112252), nnz=556, density=0.00%)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data_path = '/kaggle/input/kg-final/kg_final.txt' # Data path\ndf = pd.read_csv(data_path, sep=\" \", header=None, names=['h', 'r', 't'])\ndf = df[df['h'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - field relastionships.\nother_mapping = {other: idx for idx, other in enumerate(df['t'].unique())}\ndf['t'] = df['t'].map(other_mapping)\n\n# Prepare course - field edge index\ncourse_col = torch.tensor(df['h'].values, dtype=torch.int64)\nother_col = torch.tensor(df['t'].values, dtype=torch.int64)\nother_edge_type = torch.tensor(df['r'].values, dtype=torch.int64) + 2\ncourse_other_edge_index = torch.stack([course_col, other_col], dim=0) # Create course - field edge index\nnum_others = len(other_mapping)\n\ncourse_other_sparse_edge_index = SparseTensor(\n    col = other_col + num_users + num_courses,\n    row = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_others, num_users + num_courses + num_others)\n)\n\nprint(course_other_sparse_edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:35:38.730377Z","iopub.execute_input":"2024-12-08T02:35:38.731105Z","iopub.status.idle":"2024-12-08T02:35:38.792898Z","shell.execute_reply.started":"2024-12-08T02:35:38.731061Z","shell.execute_reply":"2024-12-08T02:35:38.792040Z"}},"outputs":[{"name":"stdout","text":"SparseTensor(row=tensor([ 99970,  99970,  99971,  ..., 102795, 102795, 102796]),\n             col=tensor([103207, 106885, 102821,  ..., 103236, 107473, 103124]),\n             size=(110265, 110265), nnz=68772, density=0.00%)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"concat_row = torch.cat([train_sparse_edge_index.storage.row(), train_sparse_edge_index.storage.col(), course_other_sparse_edge_index.storage.row()], dim=0)\nconcat_col = torch.cat([train_sparse_edge_index.storage.col(), train_sparse_edge_index.storage.row(), course_other_sparse_edge_index.storage.col()], dim=0)\n\nedge_type = torch.cat([torch.zeros_like(train_sparse_edge_index.storage.row()), torch.ones_like(train_sparse_edge_index.storage.col()), other_edge_type], dim=0)\n\nnum_nodes = max(concat_row.max().item(), concat_col.max().item()) + 1\nconcatenated_sparse_edge_index = SparseTensor(\n    row=concat_row,\n    col=concat_col,\n    sparse_sizes=(num_nodes, num_nodes)\n)\n\nprint(concatenated_sparse_edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:35:38.795043Z","iopub.execute_input":"2024-12-08T02:35:38.795469Z","iopub.status.idle":"2024-12-08T02:35:39.130028Z","shell.execute_reply.started":"2024-12-08T02:35:38.795430Z","shell.execute_reply":"2024-12-08T02:35:39.128890Z"}},"outputs":[{"name":"stdout","text":"SparseTensor(row=tensor([     0,      0,      0,  ..., 102795, 102796, 102796]),\n             col=tensor([ 99970,  99971,  99972,  ..., 107473,  96170, 103124]),\n             size=(110265, 110265), nnz=3661672, density=0.03%)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch_geometric.nn import GATv2Conv\n\nclass HeteroGATModel(nn.Module):\n    def __init__(self, in_dim = 64, hidden_dim = 32, out_dim = 16, num_layers = 3, heads=2, dropout=0.3):\n        super(HeteroGATModel, self).__init__()\n\n        # Define embeddings for each type of node\n        self.user_entities_embeddings = nn.Embedding(num_users + num_courses + num_others, in_dim)\n        self.gat_layers = nn.ModuleList()\n\n        self.gat_layers.append(GATv2Conv(in_dim, hidden_dim, heads=heads, dropout=dropout, add_self_loops=False))\n        for _ in range(num_layers - 2):\n            self.gat_layers.append(GATv2Conv(hidden_dim * heads, hidden_dim, heads=heads, dropout=dropout, add_self_loops=False))\n        self.gat_layers.append(GATv2Conv(hidden_dim * heads, out_dim, heads=1, concat=False, dropout=dropout, add_self_loops=False))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        # Initialize embeddings\n        nn.init.xavier_uniform_(self.user_entities_embeddings.weight)\n\n        for gat_layer in self.gat_layers:\n            gat_layer.reset_parameters()\n\n    def forward(self, edge_index):\n        x_initial = self.user_entities_embeddings.weight\n        x = x_initial.clone()  # Clone để giữ nguyên embedding ban đầu\n\n        for gat_layer in self.gat_layers[:-1]:\n            x = F.elu(gat_layer(x, edge_index))\n\n        x = self.gat_layers[-1](x, edge_index)\n\n        user_emb_final, course_emb_final, other_emb_final = torch.split(x, [num_users, num_courses, num_others], dim=0)\n        user_emb_initial, course_emb_initial, _  = torch.split(x_initial, [num_users, num_courses, num_others], dim=0)\n        \n        return user_emb_final, user_emb_initial, course_emb_final, course_emb_initial, other_emb_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:35:39.131155Z","iopub.execute_input":"2024-12-08T02:35:39.131440Z","iopub.status.idle":"2024-12-08T02:35:39.140148Z","shell.execute_reply.started":"2024-12-08T02:35:39.131413Z","shell.execute_reply":"2024-12-08T02:35:39.139309Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def RecallPrecision_at_K(groundTruth, r, k):\n    num_correct_pred = torch.sum(r, dim=-1)\n    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n    recall = torch.mean(num_correct_pred / user_num_liked)\n    precision = torch.mean(num_correct_pred) / k\n    \n    return recall.item(), precision.item()\n\ndef NDCG_at_K(groundTruth, r, k):\n    assert len(r) == len(groundTruth)\n    test_matrix = torch.zeros((len(r), k))\n    for i, items in enumerate(groundTruth):\n        length = min(len(items), k)\n        test_matrix[i, :length] = 1\n    max_r = test_matrix\n    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n    dcg = torch.sum(dcg, axis=1)\n    idcg[idcg == 0.] = 1.\n    ndcg = dcg / idcg\n    ndcg[torch.isnan(ndcg)] = 0.\n    #\n    return torch.mean(ndcg).item()\n\ndef get_user_positive_items(edge_index):\n    user_pos_items = {}\n    for i in range(edge_index.shape[1]):\n        user = edge_index[0][i].item()\n        item = edge_index[1][i].item()\n        if user not in user_pos_items:\n            user_pos_items[user] = []\n        user_pos_items[user].append(item)\n        \n    return user_pos_items\n\nfrom torch_geometric.utils import negative_sampling\n\nfrom tqdm import tqdm\n\ndef get_metrics_with_negative_sampling(\n    model, edge_index, sparse_edge_index, exclude_edge_index, train_sparse_edge_index, k, num_neg_samples=100\n):\n    \"\"\"\n    Evaluate the model using explicit negative sampling.\n    \n    Parameters:\n        - model: The trained model.\n        - edge_index: Test edge index (user-item interactions).\n        - sparse_edge_index: Sparse test edge matrix.\n        - exclude_edge_index: Edges to exclude (train + validation).\n        - train_sparse_edge_index: Sparse adjacency matrix for training.\n        - k: Number of top items to evaluate (Recall@K, etc.).\n        - num_neg_samples: Number of negative samples per user.\n    Returns:\n        - recall, precision, ndcg\n    \"\"\"\n    model.eval()\n    # Get user and item embeddings\n    user_embedding, _, item_embedding, _, _ = model.forward(train_sparse_edge_index)\n    user_embedding = user_embedding.cpu().detach().numpy()\n    item_embedding = item_embedding.cpu().detach().numpy()\n    \n    rating = torch.tensor(np.matmul(user_embedding, item_embedding.T))\n\n    # Mask out all positive interactions from train and test data\n    user_pos_items = get_user_positive_items(exclude_edge_index)\n    exclude_users = []\n    exclude_items = []\n    for user, items in user_pos_items.items():\n        exclude_users.extend([user] * len(items))\n        exclude_items.extend(items)\n    rating[exclude_users, exclude_items] = float('-inf')\n\n    # Generate negative samples\n    num_users = rating.shape[0]\n    num_items = rating.shape[1]\n    all_items = torch.arange(num_items)\n    neg_samples = {}\n    for user in range(num_users):\n        pos_items = set(user_pos_items.get(user, []))\n        neg_items = list(set(all_items.tolist()) - pos_items)\n        neg_samples[user] = torch.tensor(neg_items, dtype=torch.long)[\n            torch.randperm(len(neg_items))[:num_neg_samples]\n        ]\n\n    # Evaluate on positive test items + negative samples\n    users = edge_index[0].unique()\n    test_user_pos_items = get_user_positive_items(edge_index)\n    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n    \n    recall = 0.0\n    precision = 0.0\n    ndcg = 0.0\n\n    for user in users:\n        user = user.item()\n        # Combine test positives and sampled negatives\n        test_items = set(test_user_pos_items.get(user, []))\n        sampled_items = list(test_items.union(neg_samples[user].tolist()))\n        \n        # Get top-K recommendations\n        user_ratings = rating[user, sampled_items]\n        _, top_K_items = torch.topk(user_ratings, k=k)\n        top_K_items = [sampled_items[i] for i in top_K_items]\n\n        # Create relevance vector\n        ground_truth_items = set(test_user_pos_items.get(user, []))\n        relevance = torch.tensor(\n            [1.0 if item in ground_truth_items else 0.0 for item in top_K_items]\n        )\n\n        # Calculate metrics\n        recall += torch.sum(relevance) / len(ground_truth_items)\n        precision += torch.sum(relevance) / k\n\n        # Calculate NDCG\n        gains = relevance / torch.log2(torch.arange(2, k + 2).float())\n        dcg = torch.sum(gains)\n        ideal_gains = torch.zeros_like(relevance)\n        ideal_gains[: len(ground_truth_items)] = 1.0\n        idcg = torch.sum(ideal_gains / torch.log2(torch.arange(2, k + 2).float()))\n        ndcg += dcg / idcg\n\n    num_users = len(users)\n    recall /= num_users\n    precision /= num_users\n    ndcg /= num_users\n\n    return recall, precision, ndcg\n\ndef bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_):\n    reg_loss = lambda_ * (users_emb_0.norm(2).pow(2) +\n                          pos_items_emb_0.norm(2).pow(2) +\n                          neg_items_emb_0.norm(2).pow(2)) # L2 loss\n\n    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n    pos_scores = torch.sum(pos_scores, dim=-1)\n    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n    neg_scores = torch.sum(neg_scores, dim=-1)\n    \n    loss = -F.logsigmoid(pos_scores - neg_scores).sum() + reg_loss\n    \n    return loss\n\nimport torch\nimport torch.nn.functional as F\n\ndef custom_negative_sampling(edge_index, num_nodes, num_neg_samples):\n    \"\"\"\n    edge_index: Sparse edge indices of the graph (positive edges)\n    num_nodes: Total number of nodes in the graph\n    num_neg_samples: Number of negative samples per positive sample\n    num_users: Number of user nodes in the graph\n    num_courses: Number of course nodes in the graph\n    \"\"\"\n    # Extract rows and columns from edge_index\n    row, col = edge_index\n    row_device = row.device  # Ensure device compatibility\n\n    # Sample negative nodes outside the user-course range\n    valid_neg_nodes = torch.cat([\n        torch.arange(num_users, device=row_device),\n        torch.arange(num_users + num_courses, num_nodes, device=row_device)  \n    ])\n    \n    neg_col = valid_neg_nodes[torch.randint(0, valid_neg_nodes.size(0), (row.size(0) * num_neg_samples,))]\n\n    # Ensure negative samples are unique and do not overlap with positive edges\n    mask = torch.isin(neg_col, col)  # Overlap with existing edges\n    while mask.any():\n        neg_col[mask] = valid_neg_nodes[\n            torch.randint(0, valid_neg_nodes.size(0), (mask.sum(),))\n        ]\n        mask = torch.isin(neg_col, col)  # Recheck for overlaps\n\n    # Construct negative edge index\n    neg_edge_index = torch.stack([row.repeat_interleave(num_neg_samples), neg_col]).t()\n\n    return neg_edge_index\n","metadata":{"execution":{"iopub.status.busy":"2024-12-08T02:39:18.445936Z","iopub.execute_input":"2024-12-08T02:39:18.446289Z","iopub.status.idle":"2024-12-08T02:39:18.467330Z","shell.execute_reply.started":"2024-12-08T02:39:18.446257Z","shell.execute_reply":"2024-12-08T02:39:18.466285Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\ntorch.autograd.set_detect_anomaly(True)\nfrom torch.utils.data import DataLoader\nfrom torch_geometric.utils import negative_sampling\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Parameters\nepochs = 20  # Number of epochs\ncheck_step = 4  # Evaluate every `check_step` epochs\nbatch_size = 2048  # Batch size for training\nlambda_ = 0.0001  # Regularization parameter\n\n# Initialize the model, optimizer, and other components\nmodel = HeteroGATModel(in_dim = 32, hidden_dim = 64, out_dim = 32, num_layers = 2, heads=1, dropout=0.3)\nmodel.to(device)  # Move the model to the device (GPU or CPU)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)\nkg_optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)\n\nfor epoch in range(1, epochs + 1):\n    model.train()\n    trn_loader = DataLoader(train_edge_index.T, batch_size=batch_size, shuffle=True)\n    trn_loss = 0\n\n    # Wrap the DataLoader in tqdm to track batches\n    batch_bar = tqdm(trn_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n    for batch_idx, batch_pos_edges in enumerate(batch_bar):\n        batch_pos_edges = batch_pos_edges.T\n        batch_pos_edges = batch_pos_edges.to(device)  # Move batch to device\n\n        # Forward pass with multiple adjacency matrices\n        user_emb_final, user_emb_initial, course_emb_final, course_emb_initial, other_emb_final = model.forward(\n            concatenated_sparse_edge_index.to(device)\n        )\n\n        # Generate negative samples for the batch\n        batch_neg_edges = negative_sampling(\n            train_edge_index.to(device),  # Ensure train_edge_index is on the same device\n            num_nodes=[num_users, num_courses],\n            num_neg_samples=batch_pos_edges.shape[1],\n        ).to(device)  # Ensure negative samples are on the same device\n\n        # Extract indices for users, positive items, and negative items\n        user_indices = batch_pos_edges[0].to(device)\n        pos_item_indices = batch_pos_edges[1].to(device)\n        neg_item_indices = batch_neg_edges[1].to(device)\n\n        # Embed users and items based on the indices\n        users_emb_final = user_emb_final[user_indices]\n        users_emb_initial = user_emb_initial[user_indices]\n        pos_items_emb_final = course_emb_final[pos_item_indices]\n        neg_items_emb_final = course_emb_final[neg_item_indices]\n        pos_items_emb_initial = course_emb_initial[pos_item_indices]\n        neg_items_emb_initial = course_emb_initial[neg_item_indices]\n\n        # Calculate BPR loss\n        loss = bpr_loss(\n            users_emb_final, \n            users_emb_initial, \n            pos_items_emb_final, \n            pos_items_emb_initial, \n            neg_items_emb_final, \n            neg_items_emb_initial, \n            lambda_\n        )\n\n        all_emb_final = torch.cat([user_emb_final, course_emb_final, other_emb_final], dim=0)\n        \n        row_indices = concatenated_sparse_edge_index.storage.row().to(device)\n        col_indices = concatenated_sparse_edge_index.storage.col().to(device)\n    \n        mask = torch.isin(row_indices, batch_pos_edges[1])\n    \n        course_indices = row_indices[mask]\n        other_indices = col_indices[mask]\n    \n        pos_edge_index = torch.stack([course_indices, other_indices], dim=0).to(device)\n    \n        # Negative sampling\n        neg_edge_index= custom_negative_sampling(\n            pos_edge_index, num_users + num_courses + num_others, 1\n        )\n\n        del row_indices\n        del col_indices\n    \n        pos_course_emb = all_emb_final[course_indices].to(device)\n        pos_other_emb = all_emb_final[other_indices].to(device)\n    \n        neg_row_indices = neg_edge_index[:, 0].to(device)\n        neg_col_indices = neg_edge_index[:, 1].to(device)\n\n        neg_course_emb = all_emb_final[neg_row_indices].to(device)\n        neg_other_emb = all_emb_final[neg_col_indices].to(device)  # Negative samples\n    \n        # Positive and negative scores\n        other_pos_scores = torch.sum(pos_course_emb * pos_other_emb, dim=1)\n        other_neg_scores = torch.sum(neg_course_emb * neg_other_emb, dim=1)\n        \n        kg_loss = torch.mean(torch.clamp(1 - other_pos_scores, min=0)) + \\\n                  torch.mean(torch.clamp(other_neg_scores + 1, min=0))\n\n        optimizer.zero_grad()\n        loss.backward(retain_graph=True)\n        optimizer.step()\n        kg_optimizer.zero_grad()\n        kg_loss.backward()\n        optimizer.step()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        trn_loss += loss.item() + kg_loss.item()\n\n        # Update tqdm with current batch loss\n        batch_bar.set_postfix(batch_loss=loss.item() + kg_loss.item())\n\n    trn_loss = trn_loss / len(trn_loader)\n    print(f\"Epoch {epoch}/{epochs} - Training loss: {trn_loss:.6f}\")\n\n    # Evaluate and display metrics every `check_step` epochs\n    if epoch != 0 and epoch % check_step == 0:\n        model.eval()\n        recall, precision, ndcg = get_metrics_with_negative_sampling(\n            model, \n            test_edge_index.to(device),  \n            test_sparse_edge_index.to(device),\n            train_edge_index.to(device),  \n            concatenated_sparse_edge_index.to(device),\n            k=10\n        )\n        score = 0.75 * recall + 0.25 * ndcg\n\n        print(f'[{epoch:03d}/{epochs}] | loss: {trn_loss:.6f} | recall@{10}: {recall:.6f} | '\n              f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"execution":{"iopub.status.busy":"2024-12-08T02:39:20.331549Z","iopub.execute_input":"2024-12-08T02:39:20.331996Z","iopub.status.idle":"2024-12-08T05:35:31.896324Z","shell.execute_reply.started":"2024-12-08T02:39:20.331953Z","shell.execute_reply":"2024-12-08T05:35:31.895413Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20 - Training loss: 416.945478\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20 - Training loss: 345.266812\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20 - Training loss: 318.292358\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20 - Training loss: 308.925775\n[004/20] | loss: 308.925775 | recall@10: 0.688457 | precision@10: 0.068889 | ndcg@10: 0.438694 | score: 0.626016\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20 - Training loss: 302.039998\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20 - Training loss: 296.478986\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20 - Training loss: 291.104120\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20 - Training loss: 287.910858\n[008/20] | loss: 287.910858 | recall@10: 0.709603 | precision@10: 0.071006 | ndcg@10: 0.456832 | score: 0.646410\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20 - Training loss: 285.262570\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20 - Training loss: 283.220161\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20 - Training loss: 281.677064\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20 - Training loss: 277.929774\n[012/20] | loss: 277.929774 | recall@10: 0.707412 | precision@10: 0.070787 | ndcg@10: 0.458602 | score: 0.645210\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20 - Training loss: 276.604000\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20 - Training loss: 275.886061\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20 - Training loss: 273.542927\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20 - Training loss: 273.401425\n[016/20] | loss: 273.401425 | recall@10: 0.711834 | precision@10: 0.071229 | ndcg@10: 0.462561 | score: 0.649515\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20 - Training loss: 271.669259\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20 - Training loss: 270.561712\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20 - Training loss: 269.489528\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20 - Training loss: 266.750974\n[020/20] | loss: 266.750974 | recall@10: 0.712614 | precision@10: 0.071307 | ndcg@10: 0.465716 | score: 0.650889\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.eval()\nrecall, precision, ndcg = get_metrics_with_negative_sampling(\n    model, \n    test_edge_index.to(device),\n    test_sparse_edge_index.to(device),\n    train_edge_index.to(device),\n    concatenated_sparse_edge_index.to(device),\n    k=10\n)\nscore = 0.75 * recall + 0.25 * ndcg\n\nprint(f'| recall@{10}: {recall:.6f} | '\n      f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:39:42.938330Z","iopub.execute_input":"2024-12-08T05:39:42.939123Z","iopub.status.idle":"2024-12-08T05:41:48.087957Z","shell.execute_reply.started":"2024-12-08T05:39:42.939091Z","shell.execute_reply":"2024-12-08T05:41:48.087160Z"}},"outputs":[{"name":"stdout","text":"| recall@10: 0.712444 | precision@10: 0.071290 | ndcg@10: 0.466541 | score: 0.650968\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model.eval()\nrecall, precision, ndcg = get_metrics_with_negative_sampling(\n    model, \n    test_edge_index.to(device),\n    test_sparse_edge_index.to(device),\n    train_edge_index.to(device),\n    concatenated_sparse_edge_index.to(device),\n    k=5\n)\nscore = 0.75 * recall + 0.25 * ndcg\n\nprint(f'| recall@{10}: {recall:.6f} | '\n      f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:47:32.563374Z","iopub.execute_input":"2024-12-08T05:47:32.564204Z","iopub.status.idle":"2024-12-08T05:49:36.381767Z","shell.execute_reply.started":"2024-12-08T05:47:32.564169Z","shell.execute_reply":"2024-12-08T05:49:36.380808Z"}},"outputs":[{"name":"stdout","text":"| recall@10: 0.567740 | precision@10: 0.113612 | ndcg@10: 0.419945 | score: 0.530791\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.eval()\nrecall, precision, ndcg = get_metrics_with_negative_sampling(\n    model, \n    test_edge_index.to(device),\n    test_sparse_edge_index.to(device),\n    train_edge_index.to(device),\n    concatenated_sparse_edge_index.to(device),\n    k=1\n)\nscore = 0.75 * recall + 0.25 * ndcg\n\nprint(f'| recall@{10}: {recall:.6f} | '\n      f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:49:36.383653Z","iopub.execute_input":"2024-12-08T05:49:36.384014Z","iopub.status.idle":"2024-12-08T05:51:38.152051Z","shell.execute_reply.started":"2024-12-08T05:49:36.383976Z","shell.execute_reply":"2024-12-08T05:51:38.151141Z"}},"outputs":[{"name":"stdout","text":"| recall@10: 0.258778 | precision@10: 0.258778 | ndcg@10: 0.258778 | score: 0.258778\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"data_path = '/kaggle/input/mooccubex/test_df.csv'\ndf = pd.read_csv(data_path)\ndf = df[df['test_label'] < num_courses]\n\ntest_user_col = torch.tensor(df['user'].values, dtype=torch.int64)\ntest_course_col = torch.tensor(df['test_label'].values, dtype=torch.int64)\n\ntest_edge_index = torch.stack([test_user_col, test_course_col], dim=0)\n\ntest_course_col_shifted = test_course_col + num_users\ntest_sparse_edge_index = SparseTensor(\n    row=test_user_col,\n    col=test_course_col_shifted,\n    sparse_sizes=(num_users + num_courses, num_users + num_courses)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:51:38.152963Z","iopub.execute_input":"2024-12-08T05:51:38.153187Z","iopub.status.idle":"2024-12-08T05:51:38.264945Z","shell.execute_reply.started":"2024-12-08T05:51:38.153165Z","shell.execute_reply":"2024-12-08T05:51:38.264050Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model.eval()\nrecall, precision, ndcg = get_metrics_with_negative_sampling(\n    model, \n    test_edge_index.to(device),\n    test_sparse_edge_index.to(device),\n    train_edge_index.to(device),\n    concatenated_sparse_edge_index.to(device),\n    k=10\n)\nscore = 0.75 * recall + 0.25 * ndcg\n\nprint(f'| recall@{10}: {recall:.6f} | '\n      f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:51:38.266469Z","iopub.execute_input":"2024-12-08T05:51:38.266751Z","iopub.status.idle":"2024-12-08T05:53:43.421056Z","shell.execute_reply.started":"2024-12-08T05:51:38.266725Z","shell.execute_reply":"2024-12-08T05:53:43.420222Z"}},"outputs":[{"name":"stdout","text":"| recall@10: 0.660064 | precision@10: 0.066047 | ndcg@10: 0.416637 | score: 0.599208\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model.eval()\nrecall, precision, ndcg = get_metrics_with_negative_sampling(\n    model, \n    test_edge_index.to(device),\n    test_sparse_edge_index.to(device),\n    train_edge_index.to(device),\n    concatenated_sparse_edge_index.to(device),\n    k=5\n)\nscore = 0.75 * recall + 0.25 * ndcg\n\nprint(f'| recall@{10}: {recall:.6f} | '\n      f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:53:43.422098Z","iopub.execute_input":"2024-12-08T05:53:43.422366Z","iopub.status.idle":"2024-12-08T05:55:47.116869Z","shell.execute_reply.started":"2024-12-08T05:53:43.422335Z","shell.execute_reply":"2024-12-08T05:55:47.115880Z"}},"outputs":[{"name":"stdout","text":"| recall@10: 0.508328 | precision@10: 0.101718 | ndcg@10: 0.367275 | score: 0.473065\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model.eval()\nrecall, precision, ndcg = get_metrics_with_negative_sampling(\n    model, \n    test_edge_index.to(device),\n    test_sparse_edge_index.to(device),\n    train_edge_index.to(device),\n    concatenated_sparse_edge_index.to(device),\n    k=1\n)\nscore = 0.75 * recall + 0.25 * ndcg\n\nprint(f'| recall@{10}: {recall:.6f} | '\n      f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:55:47.117968Z","iopub.execute_input":"2024-12-08T05:55:47.118226Z","iopub.status.idle":"2024-12-08T05:57:48.676041Z","shell.execute_reply.started":"2024-12-08T05:55:47.118200Z","shell.execute_reply":"2024-12-08T05:57:48.675209Z"}},"outputs":[{"name":"stdout","text":"| recall@10: 0.215470 | precision@10: 0.215470 | ndcg@10: 0.215470 | score: 0.215470\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"checkpoint = {'model': HeteroGATModel(in_dim = 32, hidden_dim = 64, out_dim = 32, num_layers = 2, heads=1, dropout=0.3),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict(),\n              'kg_optimizer': kg_optimizer.state_dict()\n             }\n\ntorch.save(checkpoint, 'checkpoint.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:00:15.865745Z","iopub.execute_input":"2024-12-08T06:00:15.866085Z","iopub.status.idle":"2024-12-08T06:00:15.986115Z","shell.execute_reply.started":"2024-12-08T06:00:15.866056Z","shell.execute_reply":"2024-12-08T06:00:15.985173Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!pip install googletrans==4.0.0-rc1\nfrom googletrans import Translator\n\ntranslator = Translator()\n\ndef translate_column(df, column_name):\n    \"\"\"\n    Translates the text in a specified column of the DataFrame to the desired language.\n\n    Args:\n        df (pd.DataFrame): The DataFrame containing the column to translate.\n        column_name (str): The name of the column to translate.\n\n    Returns:\n        pd.DataFrame: DataFrame with the translated column.\n    \"\"\"\n    df[column_name] = df[column_name].apply(\n        lambda text: translator.translate(text = text, src='zh-CN', dest='vi').text if pd.notna(text) else text\n    )\n    \n    return df\n\ndef recommend_courses_for_user(\n    model, user_id, train_sparse_edge_index, exclude_edge_index, top_k=10\n):\n    \"\"\"\n    Recommend courses for a given user ID.\n    \n    Parameters:\n        - model: The trained recommendation model.\n        - user_id: The user ID to generate recommendations for.\n        - train_sparse_edge_index: Sparse adjacency matrix for training.\n        - exclude_edge_index: Edges to exclude (train + validation interactions).\n        - top_k: Number of top items to recommend (default: 10).\n    \n    Returns:\n        - A list of top_k recommended course IDs.\n    \"\"\"\n    model.eval()\n\n    # Get user and item embeddings\n    user_embedding, _, item_embedding, _, _ = model.forward(train_sparse_edge_index)\n    user_embedding = user_embedding.cpu().detach().numpy()\n    item_embedding = item_embedding.cpu().detach().numpy()\n\n    # Compute scores for all items for the given user\n    user_vector = user_embedding[user_id]\n    scores = np.dot(user_vector, item_embedding.T)\n\n    # Mask out already interacted items\n    user_pos_items = get_user_positive_items(exclude_edge_index)\n    exclude_items = set(user_pos_items.get(user_id, []))\n    scores[list(exclude_items)] = float('-inf')  # Set scores for interacted items to -inf\n\n    # Get the top-K items\n    top_k_items = np.argsort(-scores)[:top_k]  # Sort in descending order and pick top K\n\n    return top_k_items\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:23:15.654514Z","iopub.execute_input":"2024-12-08T06:23:15.654836Z","iopub.status.idle":"2024-12-08T06:23:15.660871Z","shell.execute_reply.started":"2024-12-08T06:23:15.654812Z","shell.execute_reply":"2024-12-08T06:23:15.660028Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"user_id = 123\nrecommended_courses = recommend_courses_for_user(\n    model,\n    user_id=user_id,\n    train_sparse_edge_index=concatenated_sparse_edge_index.to(device),\n    exclude_edge_index=torch.cat([train_edge_index, test_edge_index], dim = -1).to(device),\n    top_k=10\n)\n\nprint(f\"Recommended courses for user {user_id}: {recommended_courses}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:23:17.586000Z","iopub.execute_input":"2024-12-08T06:23:17.586802Z","iopub.status.idle":"2024-12-08T06:24:17.611178Z","shell.execute_reply.started":"2024-12-08T06:23:17.586770Z","shell.execute_reply":"2024-12-08T06:24:17.610271Z"}},"outputs":[{"name":"stdout","text":"Recommended courses for user 123: [1956 2342 2699 1966  497  422 2293 2055 2330  697]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"course_map_path = \"/kaggle/input/mooccubex/course_map.csv\"\ncourse_prepared_path = \"/kaggle/input/mooccubex/course_prepared.json\"\n\n# Read data\ncourse_map = pd.read_csv(course_map_path, names=['course', 'map'])\ncourse_mapping = dict(zip(course_map[\"course\"], course_map[\"map\"]))\ncourse_prepared = pd.read_json(course_prepared_path, lines = True)\ncourse_prepared[\"id\"] = course_prepared[\"id\"].map(course_mapping)\ncourse_prepared = course_prepared.dropna(subset=[\"id\"])\n\npredicted_course = course_prepared[course_prepared['id'].isin(recommended_courses)]\ntranslate_column(predicted_course, 'name')\ntranslate_column(predicted_course, 'prerequisites')\ntranslate_column(predicted_course, 'about')\n\npredicted_course","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:45:34.115012Z","iopub.execute_input":"2024-12-08T06:45:34.115313Z","iopub.status.idle":"2024-12-08T06:46:02.056769Z","shell.execute_reply.started":"2024-12-08T06:45:34.115289Z","shell.execute_reply":"2024-12-08T06:46:02.055886Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2266137368.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[column_name] = df[column_name].apply(\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"          id                              name  \\\n760    497.0           Cấu trúc xây dựng nhà ở   \n1171   422.0              Nhà thiết kế tinh tế   \n1617  2055.0                Công nghệ xây dựng   \n2222  2342.0                Công nghệ xây dựng   \n2278  1966.0              Thiết kế mẫu quần áo   \n2281  2330.0           Thiết kế trang phục nam   \n2537  1956.0                Thiết kế phác thảo   \n2765  2293.0  21 Lớp học tiếng Anh sau đại học   \n2821   697.0                    Sơ đồ kỹ thuật   \n3215  2699.0                   Kiến trúc nhà ở   \n\n                                          prerequisites  \\\n760                        Vẽ và hiểu kỹ thuật xây dựng   \n1171                                               None   \n1617  Làm chủ kiến ​​thức liên quan về hình ảnh kiến...   \n2222  Các khóa học công nghệ xây dựng là một khóa họ...   \n2278                                               None   \n2281                                               None   \n2537                      \"Phác thảo cơ bản\", Quan điểm   \n2765                                               None   \n2821                                               None   \n3215                                               None   \n\n                                                  about  \\\n760   Cấu trúc xây dựng của ngôi nhà là một khóa học...   \n1171  Nhà là một container cho cuộc sống.Làm thế nào...   \n1617  Bạn muốn tìm hiểu các phương pháp xây dựng và ...   \n2222  Công nghệ xây dựng là một khóa học cốt lõi chu...   \n2278  Khóa học là khóa học cốt lõi của trường và đan...   \n2281  \"Trong giảng dạy đại học truyền thống, kết hợp...   \n2537  Phim và truyền hình, quần áo, quảng cáo, trong...   \n2765                   21 Lớp học tiếng Anh sau đại học   \n2821  Các khóa học vẽ kỹ thuật không chỉ dạy bạn xem...   \n3215  Cuộc sống của mọi người có liên quan chặt chẽ ...   \n\n                                               resource   field   schools  \\\n760   [{'titles': ['第一章\t绪论', '1.1 建筑的基本要素', '1.1.1 建...    None    [S_49]   \n1171  [{'titles': ['导论', '绪论', '绪论'], 'resource_id':...   [建筑学]     [S_1]   \n1617  [{'titles': ['项目一：土方工程施工', '任务1.1土的工程分类', '任务1...    None   [S_513]   \n2222  [{'titles': ['项目一 土方工程施工', '1.2 场地平整', '场地平整']...    None   [S_669]   \n2278  [{'titles': ['第一章   概论', '1.1\t概论', '1.1视频 概论上'...    None   [S_712]   \n2281  [{'titles': ['第1章 概述', '1.1 男装设计的概念与分类', '视频录课...    None   [S_712]   \n2537  [{'titles': ['第一章 设计素描概述', '1.1 设计素描的基本特征', '1...    None  [S_1087]   \n2765  [{'titles': ['21考研英语小白课堂', None, '21考研英语备考高分秘籍...    None    [S_63]   \n2821  [{'titles': ['第一讲：第1章 绪论', '1.1 工程制图的应用背景', '1...  [机械工程]     [S_1]   \n3215  [{'titles': ['第一章 建筑设计概论', '1.1 认识建筑', '1.1 认识...    None  [S_1306]   \n\n                                               teachers  \n760   [T_2903, T_2250, T_4461, T_4459, T_2251, T_290...  \n1171                [T_640, T_640, T_640, T_640, T_640]  \n1617  [T_5352, T_5353, T_5354, T_5355, T_5356, T_535...  \n2222  [T_6193, T_6194, T_6195, T_6196, T_6197, T_619...  \n2278  [T_8079, T_8081, T_8083, T_8085, T_8086, T_807...  \n2281  [T_9118, T_9121, T_9127, T_9128, T_9118, T_912...  \n2537  [T_10631, T_10636, T_10632, T_10633, T_10634, ...  \n2765                                          [T_11805]  \n2821  [T_508, T_509, T_510, T_511, T_512, T_513, T_5...  \n3215                                 [T_13604, T_13604]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>prerequisites</th>\n      <th>about</th>\n      <th>resource</th>\n      <th>field</th>\n      <th>schools</th>\n      <th>teachers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>760</th>\n      <td>497.0</td>\n      <td>Cấu trúc xây dựng nhà ở</td>\n      <td>Vẽ và hiểu kỹ thuật xây dựng</td>\n      <td>Cấu trúc xây dựng của ngôi nhà là một khóa học...</td>\n      <td>[{'titles': ['第一章\t绪论', '1.1 建筑的基本要素', '1.1.1 建...</td>\n      <td>None</td>\n      <td>[S_49]</td>\n      <td>[T_2903, T_2250, T_4461, T_4459, T_2251, T_290...</td>\n    </tr>\n    <tr>\n      <th>1171</th>\n      <td>422.0</td>\n      <td>Nhà thiết kế tinh tế</td>\n      <td>None</td>\n      <td>Nhà là một container cho cuộc sống.Làm thế nào...</td>\n      <td>[{'titles': ['导论', '绪论', '绪论'], 'resource_id':...</td>\n      <td>[建筑学]</td>\n      <td>[S_1]</td>\n      <td>[T_640, T_640, T_640, T_640, T_640]</td>\n    </tr>\n    <tr>\n      <th>1617</th>\n      <td>2055.0</td>\n      <td>Công nghệ xây dựng</td>\n      <td>Làm chủ kiến ​​thức liên quan về hình ảnh kiến...</td>\n      <td>Bạn muốn tìm hiểu các phương pháp xây dựng và ...</td>\n      <td>[{'titles': ['项目一：土方工程施工', '任务1.1土的工程分类', '任务1...</td>\n      <td>None</td>\n      <td>[S_513]</td>\n      <td>[T_5352, T_5353, T_5354, T_5355, T_5356, T_535...</td>\n    </tr>\n    <tr>\n      <th>2222</th>\n      <td>2342.0</td>\n      <td>Công nghệ xây dựng</td>\n      <td>Các khóa học công nghệ xây dựng là một khóa họ...</td>\n      <td>Công nghệ xây dựng là một khóa học cốt lõi chu...</td>\n      <td>[{'titles': ['项目一 土方工程施工', '1.2 场地平整', '场地平整']...</td>\n      <td>None</td>\n      <td>[S_669]</td>\n      <td>[T_6193, T_6194, T_6195, T_6196, T_6197, T_619...</td>\n    </tr>\n    <tr>\n      <th>2278</th>\n      <td>1966.0</td>\n      <td>Thiết kế mẫu quần áo</td>\n      <td>None</td>\n      <td>Khóa học là khóa học cốt lõi của trường và đan...</td>\n      <td>[{'titles': ['第一章   概论', '1.1\t概论', '1.1视频 概论上'...</td>\n      <td>None</td>\n      <td>[S_712]</td>\n      <td>[T_8079, T_8081, T_8083, T_8085, T_8086, T_807...</td>\n    </tr>\n    <tr>\n      <th>2281</th>\n      <td>2330.0</td>\n      <td>Thiết kế trang phục nam</td>\n      <td>None</td>\n      <td>\"Trong giảng dạy đại học truyền thống, kết hợp...</td>\n      <td>[{'titles': ['第1章 概述', '1.1 男装设计的概念与分类', '视频录课...</td>\n      <td>None</td>\n      <td>[S_712]</td>\n      <td>[T_9118, T_9121, T_9127, T_9128, T_9118, T_912...</td>\n    </tr>\n    <tr>\n      <th>2537</th>\n      <td>1956.0</td>\n      <td>Thiết kế phác thảo</td>\n      <td>\"Phác thảo cơ bản\", Quan điểm</td>\n      <td>Phim và truyền hình, quần áo, quảng cáo, trong...</td>\n      <td>[{'titles': ['第一章 设计素描概述', '1.1 设计素描的基本特征', '1...</td>\n      <td>None</td>\n      <td>[S_1087]</td>\n      <td>[T_10631, T_10636, T_10632, T_10633, T_10634, ...</td>\n    </tr>\n    <tr>\n      <th>2765</th>\n      <td>2293.0</td>\n      <td>21 Lớp học tiếng Anh sau đại học</td>\n      <td>None</td>\n      <td>21 Lớp học tiếng Anh sau đại học</td>\n      <td>[{'titles': ['21考研英语小白课堂', None, '21考研英语备考高分秘籍...</td>\n      <td>None</td>\n      <td>[S_63]</td>\n      <td>[T_11805]</td>\n    </tr>\n    <tr>\n      <th>2821</th>\n      <td>697.0</td>\n      <td>Sơ đồ kỹ thuật</td>\n      <td>None</td>\n      <td>Các khóa học vẽ kỹ thuật không chỉ dạy bạn xem...</td>\n      <td>[{'titles': ['第一讲：第1章 绪论', '1.1 工程制图的应用背景', '1...</td>\n      <td>[机械工程]</td>\n      <td>[S_1]</td>\n      <td>[T_508, T_509, T_510, T_511, T_512, T_513, T_5...</td>\n    </tr>\n    <tr>\n      <th>3215</th>\n      <td>2699.0</td>\n      <td>Kiến trúc nhà ở</td>\n      <td>None</td>\n      <td>Cuộc sống của mọi người có liên quan chặt chẽ ...</td>\n      <td>[{'titles': ['第一章 建筑设计概论', '1.1 认识建筑', '1.1 认识...</td>\n      <td>None</td>\n      <td>[S_1306]</td>\n      <td>[T_13604, T_13604]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45}]}
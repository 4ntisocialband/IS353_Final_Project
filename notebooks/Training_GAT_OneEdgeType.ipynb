{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9878328,"sourceType":"datasetVersion","datasetId":6064823},{"sourceId":10013909,"sourceType":"datasetVersion","datasetId":6165206},{"sourceId":10063026,"sourceType":"datasetVersion","datasetId":6201470},{"sourceId":10063457,"sourceType":"datasetVersion","datasetId":6201771},{"sourceId":207926980,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall torch torchvision torchaudio -y\n!pip install torch==2.0.0+cu118 torchvision==0.15.0+cu118 torchaudio==2.0.0 -f https://download.pytorch.org/whl/torch_stable.html\n!pip install torch_geometric\n!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import nn, optim, Tensor\nfrom torch_sparse import SparseTensor, matmul\nimport torch_geometric\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.data import HeteroData\nfrom torch_geometric.utils import negative_sampling\nfrom torch_geometric.transforms import ToUndirected\nfrom torch_geometric.loader import LinkNeighborLoader\nfrom torch_geometric.nn import GATConv, to_hetero\nfrom tqdm import tqdm\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-04T14:09:19.711934Z","iopub.execute_input":"2024-12-04T14:09:19.712299Z","iopub.status.idle":"2024-12-04T14:11:43.338004Z","shell.execute_reply.started":"2024-12-04T14:09:19.712262Z","shell.execute_reply":"2024-12-04T14:11:43.337105Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nFound existing installation: torchvision 0.19.0\nUninstalling torchvision-0.19.0:\n  Successfully uninstalled torchvision-0.19.0\nFound existing installation: torchaudio 2.4.0\nUninstalling torchaudio-2.4.0:\n  Successfully uninstalled torchaudio-2.4.0\nLooking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch==2.0.0+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m425.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.15.0+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.0.0\n  Downloading https://download.pytorch.org/whl/rocm5.4.2/torchaudio-2.0.0%2Brocm5.4.2-cp310-cp310-linux_x86_64.whl (4.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.1.4)\nCollecting triton==2.0.0 (from torch==2.0.0+cu118)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0+cu118) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0+cu118) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0+cu118) (10.3.0)\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\nCollecting torchaudio==2.0.0\n  Downloading https://download.pytorch.org/whl/rocm5.3/torchaudio-2.0.0%2Brocm5.3-cp310-cp310-linux_x86_64.whl (4.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting cmake (from triton==2.0.0->torch==2.0.0+cu118)\n  Downloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nCollecting lit (from triton==2.0.0->torch==2.0.0+cu118)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0+cu118) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0+cu118) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0+cu118) (1.3.0)\nDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lit, cmake, triton, torch, torchvision, torchaudio\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.31.1 lit-18.1.8 torch-2.0.0+cu118 torchaudio-2.0.0+cu118 torchvision-0.15.0+cu118 triton-2.0.0\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.8.30)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\nLooking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\nCollecting pyg_lib\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.4.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch_cluster\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torch_spline_conv\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.6/886.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_sparse) (1.14.1)\nRequirement already satisfied: numpy<2.3,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch_sparse) (1.26.4)\nInstalling collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\nSuccessfully installed pyg_lib-0.4.0+pt20cu118 torch_cluster-1.6.3+pt20cu118 torch_scatter-2.1.2+pt20cu118 torch_sparse-0.6.18+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n/kaggle/input/mooccubex/val_df.csv\n/kaggle/input/mooccubex/mapped_n_core_user_course.csv\n/kaggle/input/mooccubex/mapped_course-school.csv\n/kaggle/input/mooccubex/mapped_course-field.csv\n/kaggle/input/mooccubex/mapped_course-teacher.csv\n/kaggle/input/mooccubex/train_df.csv\n/kaggle/input/mooccubex/test_df.csv\n/kaggle/input/d/vuthanhphong/kg-final/kg_final.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data_path = '/kaggle/input/mooccubex/train_df.csv' # Data path\ndf = pd.read_csv(data_path)\n\n# Convert course interact string from feature column to list\ndef str_to_list(x): # Function to split user's course interact list from string.\n    return x[1:-1].split(',')\n\ndf['feature'] = df['feature'].apply(str_to_list) # Apply str_to_list to course interact string.\ndf['feature'] = df['feature'].apply(lambda x: [int(i) for i in x]) # Convert every course type to int.\n\n# Drop column feature_time.\ndf = df.drop(columns=['feature_time'])\n\n# Explode df with feature column.\nexploded_df = df.explode('feature')\nexploded_df.reset_index(drop=True)\nexploded_df['feature'] = exploded_df['feature'].astype('int64')\n\n# Extract columns\nuser_col = torch.tensor(exploded_df['user'].values, dtype=torch.int64)\ncourse_col = torch.tensor(exploded_df['feature'].values, dtype=torch.int64)\n\ntrain_edge_index = torch.stack([user_col, course_col], dim=0)\n\n# Update num_users and num_courses\nnum_users = user_col.max().item() + 1\nnum_courses = course_col.max().item() + 1\n\n# Shift course indices and create SparseTensor\ntrain_sparse_edge_index = SparseTensor(\n    row = user_col,\n    col = course_col + num_users,\n    sparse_sizes=(num_users + num_courses, num_users + num_courses)\n)\n\nprint(train_sparse_edge_index)\n\ndata_path = '/kaggle/input/mooccubex/val_df.csv'\ndf = pd.read_csv(data_path)\ndf = df[df['val_label'] < num_courses]\n\ntest_user_col = torch.tensor(df['user'].values, dtype=torch.int64)\ntest_course_col = torch.tensor(df['val_label'].values, dtype=torch.int64)\n\ntest_edge_index = torch.stack([test_user_col, test_course_col], dim=0)\n\ntest_course_col_shifted = test_course_col + num_users\ntest_sparse_edge_index = SparseTensor(\n    row=test_user_col,\n    col=test_course_col_shifted,\n    sparse_sizes=(num_users + num_courses, num_users + num_courses)\n)\n\nprint(test_sparse_edge_index)\n\n# Load course - school data: Course - school interact\ndata_path = '/kaggle/input/mooccubex/mapped_course-school.csv' # Data path\ndf = pd.read_csv(data_path) # Read data\ndf = df[df['school'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - school relastionships.\nschool_mapping = {school: idx for idx, school in enumerate(df['school'].unique())}\ndf['school'] = df['school'].map(school_mapping)\n\n# Prepare course - school edge index\ncourse_col = torch.tensor(df['course'].values, dtype=torch.int64)\nschool_col = torch.tensor(df['school'].values, dtype=torch.int64)\ncourse_school_edge_index = torch.stack([course_col, school_col], dim=0) # Create course - school edge index\nnum_schools = len(school_mapping)\n\ncourse_school_sparse_edge_index = SparseTensor(\n    row = school_col + num_users + num_courses,\n    col = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_schools, num_users + num_courses + num_schools)\n)\n\nprint(course_school_sparse_edge_index)\n\n# Load course - teacher data: Course - teacher interact\ndata_path = '/kaggle/input/mooccubex/mapped_course-teacher.csv' # Data path\ndf = pd.read_csv(data_path) # Read data\ndf = df[df['id'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - teacher relastionships.\nteacher_mapping = {teacher: idx for idx, teacher in enumerate(df['teachers'].unique())}\ndf['teachers'] = df['teachers'].map(teacher_mapping)\n\n# Prepare course - teacher edge index\ncourse_col = torch.tensor(df['id'].values, dtype=torch.int64)\nteacher_col = torch.tensor(df['teachers'].values, dtype=torch.int64)\ncourse_teacher_edge_index = torch.stack([course_col, teacher_col], dim=0) # Create course - teacher edge index\nnum_teachers = len(teacher_mapping)\n\ncourse_teacher_sparse_edge_index = SparseTensor(\n    row = teacher_col + num_users + num_courses + num_schools,\n    col = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_schools + num_teachers, num_users + num_courses + num_schools + num_teachers)\n)\n\nprint(course_teacher_sparse_edge_index)\n\n# Load course - field data: Course - field interact\ndata_path = '/kaggle/input/mooccubex/mapped_course-field.csv' # Data path\ndf = pd.read_csv(data_path) # Read data\ndf = df[df['id'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - field relastionships.\nfield_mapping = {field: idx for idx, field in enumerate(df['field'].unique())}\ndf['field'] = df['field'].map(field_mapping)\n\n# Prepare course - field edge index\ncourse_col = torch.tensor(df['id'].values, dtype=torch.int64)\nfield_col = torch.tensor(df['field'].values, dtype=torch.int64)\ncourse_field_edge_index = torch.stack([course_col, field_col], dim=0) # Create course - field edge index\nnum_fields = len(field_mapping)\n\ncourse_field_sparse_edge_index = SparseTensor(\n    col = field_col + num_users + num_courses + num_schools + num_teachers,\n    row = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_schools + num_teachers + num_fields, num_users + num_courses + num_schools + num_teachers + num_fields)\n)\n\nprint(course_field_sparse_edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:11:43.340016Z","iopub.execute_input":"2024-12-04T14:11:43.340597Z","iopub.status.idle":"2024-12-04T14:11:46.476126Z","shell.execute_reply.started":"2024-12-04T14:11:43.340555Z","shell.execute_reply":"2024-12-04T14:11:46.475058Z"}},"outputs":[{"name":"stdout","text":"SparseTensor(row=tensor([    0,     0,     0,  ..., 99969, 99969, 99969]),\n             col=tensor([ 99970,  99971,  99972,  ..., 100235, 100410, 101954]),\n             size=(102797, 102797), nnz=1796450, density=0.02%)\nSparseTensor(row=tensor([    0,     1,     2,  ..., 99967, 99968, 99969]),\n             col=tensor([ 99973,  99971,  99975,  ..., 102158, 102045, 101687]),\n             size=(102797, 102797), nnz=99970, density=0.00%)\nSparseTensor(row=tensor([102797, 102797, 102797,  ..., 103218, 103219, 103220]),\n             col=tensor([ 99971,  99972,  99973,  ..., 101245, 101256, 101696]),\n             size=(103221, 103221), nnz=2850, density=0.00%)\nSparseTensor(row=tensor([103221, 103221, 103221,  ..., 112171, 112172, 112173]),\n             col=tensor([100216, 100318, 100603,  ..., 102608, 102608, 101696]),\n             size=(112174, 112174), nnz=10651, density=0.00%)\nSparseTensor(row=tensor([ 99972,  99973,  99979,  99979,  99981,  99982,  99982,  99984,  99986,\n                            99987,  99988,  99991,  99999, 100004, 100010, 100014, 100016, 100017,\n                           100019, 100020, 100020, 100022, 100026, 100036, 100036, 100042, 100044,\n                           100044, 100051, 100052, 100055, 100061, 100066, 100066, 100067, 100067,\n                           100068, 100068, 100068, 100071, 100074, 100077, 100083, 100092, 100094,\n                           100095, 100096, 100098, 100099, 100099, 100099, 100109, 100112, 100115,\n                           100116, 100118, 100119, 100119, 100121, 100129, 100130, 100131, 100132,\n                           100134, 100138, 100143, 100152, 100160, 100161, 100163, 100164, 100164,\n                           100165, 100165, 100166, 100167, 100168, 100171, 100172, 100172, 100173,\n                           100174, 100174, 100175, 100180, 100180, 100180, 100180, 100180, 100180,\n                           100180, 100185, 100190, 100191, 100194, 100197, 100204, 100210, 100217,\n                           100222, 100222, 100223, 100225, 100230, 100236, 100238, 100259, 100259,\n                           100259, 100272, 100278, 100279, 100279, 100283, 100284, 100284, 100288,\n                           100291, 100293, 100299, 100301, 100302, 100305, 100308, 100324, 100324,\n                           100328, 100331, 100332, 100335, 100336, 100337, 100338, 100339, 100343,\n                           100345, 100348, 100349, 100351, 100353, 100354, 100361, 100372, 100372,\n                           100373, 100391, 100392, 100395, 100395, 100395, 100395, 100396, 100397,\n                           100399, 100399, 100400, 100400, 100401, 100403, 100406, 100406, 100407,\n                           100407, 100409, 100412, 100412, 100415, 100415, 100418, 100419, 100423,\n                           100425, 100426, 100427, 100430, 100449, 100450, 100452, 100454, 100458,\n                           100459, 100459, 100462, 100478, 100479, 100480, 100481, 100483, 100491,\n                           100492, 100493, 100502, 100504, 100520, 100520, 100523, 100532, 100534,\n                           100534, 100534, 100535, 100536, 100540, 100541, 100542, 100550, 100550,\n                           100551, 100551, 100557, 100557, 100561, 100562, 100563, 100564, 100566,\n                           100567, 100567, 100574, 100575, 100580, 100582, 100582, 100585, 100601,\n                           100604, 100606, 100606, 100610, 100612, 100622, 100627, 100627, 100628,\n                           100630, 100631, 100631, 100632, 100636, 100636, 100641, 100642, 100642,\n                           100642, 100645, 100655, 100658, 100660, 100667, 100670, 100670, 100672,\n                           100675, 100675, 100677, 100683, 100684, 100686, 100686, 100686, 100687,\n                           100688, 100688, 100688, 100703, 100703, 100704, 100707, 100712, 100716,\n                           100717, 100720, 100720, 100721, 100722, 100722, 100724, 100729, 100732,\n                           100733, 100737, 100740, 100745, 100755, 100756, 100756, 100759, 100761,\n                           100761, 100762, 100767, 100767, 100773, 100776, 100779, 100780, 100780,\n                           100782, 100786, 100789, 100792, 100802, 100810, 100813, 100813, 100813,\n                           100814, 100822, 100822, 100823, 100831, 100831, 100831, 100832, 100836,\n                           100865, 100869, 100869, 100909, 100910, 100916, 100917, 100919, 100925,\n                           100935, 100935, 100937, 100938, 100938, 100944, 100951, 100954, 100956,\n                           100959, 100959, 100960, 100965, 100967, 100974, 100983, 100984, 101031,\n                           101036, 101048, 101053, 101053, 101053, 101055, 101074, 101075, 101085,\n                           101086, 101087, 101091, 101103, 101140, 101141, 101141, 101144, 101147,\n                           101152, 101152, 101153, 101153, 101155, 101200, 101209, 101240, 101240,\n                           101248, 101248, 101253, 101265, 101265, 101268, 101269, 101269, 101270,\n                           101279, 101281, 101300, 101300, 101319, 101331, 101332, 101332, 101353,\n                           101355, 101355, 101358, 101368, 101368, 101368, 101370, 101370, 101371,\n                           101372, 101376, 101385, 101388, 101389, 101391, 101399, 101402, 101410,\n                           101415, 101415, 101416, 101416, 101419, 101421, 101425, 101426, 101428,\n                           101428, 101440, 101442, 101443, 101443, 101446, 101457, 101467, 101468,\n                           101482, 101483, 101484, 101484, 101485, 101486, 101488, 101489, 101494,\n                           101494, 101502, 101503, 101504, 101504, 101506, 101507, 101532, 101533,\n                           101537, 101540, 101542, 101542, 101547, 101550, 101559, 101559, 101561,\n                           101562, 101563, 101568, 101590, 101592, 101596, 101597, 101597, 101613,\n                           101617, 101617, 101639, 101639, 101646, 101646, 101649, 101657, 101658,\n                           101659, 101670, 101671, 101673, 101676, 101676, 101680, 101697, 101699,\n                           101703, 101707, 101707, 101708, 101715, 101717, 101731, 101741, 101745,\n                           101745, 101746, 101746, 101748, 101752, 101759, 101841, 101865, 101866,\n                           101884, 101885, 101888, 101890, 101890, 101890, 101899, 101901, 101909,\n                           101922, 101944, 101955, 101957, 101967, 101969, 101982, 101990, 101998,\n                           102000, 102006, 102022, 102029, 102030, 102053, 102082, 102091, 102094,\n                           102104, 102148, 102151, 102155, 102160, 102168, 102176, 102178, 102191,\n                           102191, 102197, 102233, 102233, 102265, 102268, 102272, 102299, 102346,\n                           102351, 102371, 102387, 102435, 102446, 102446, 102490, 102490, 102535,\n                           102546, 102645, 102667, 102689, 102747, 102747, 102782]),\n             col=tensor([112193, 112182, 112175, 112215, 112193, 112218, 112247, 112226, 112243,\n                           112195, 112185, 112175, 112199, 112197, 112213, 112211, 112195, 112190,\n                           112181, 112176, 112198, 112185, 112176, 112218, 112220, 112226, 112184,\n                           112197, 112177, 112197, 112231, 112213, 112185, 112190, 112178, 112234,\n                           112182, 112183, 112184, 112180, 112193, 112226, 112193, 112226, 112176,\n                           112221, 112199, 112193, 112193, 112208, 112212, 112176, 112185, 112239,\n                           112195, 112193, 112197, 112204, 112183, 112196, 112201, 112196, 112199,\n                           112219, 112193, 112211, 112195, 112195, 112199, 112185, 112175, 112195,\n                           112184, 112195, 112226, 112226, 112226, 112195, 112206, 112226, 112239,\n                           112203, 112209, 112239, 112183, 112186, 112187, 112235, 112236, 112237,\n                           112238, 112193, 112222, 112222, 112211, 112190, 112175, 112180, 112176,\n                           112175, 112176, 112176, 112176, 112180, 112209, 112226, 112182, 112183,\n                           112184, 112176, 112181, 112210, 112216, 112177, 112175, 112195, 112199,\n                           112206, 112181, 112176, 112220, 112193, 112219, 112204, 112188, 112190,\n                           112196, 112176, 112176, 112176, 112175, 112177, 112177, 112176, 112195,\n                           112198, 112200, 112205, 112190, 112176, 112211, 112193, 112177, 112190,\n                           112175, 112204, 112204, 112178, 112194, 112224, 112230, 112177, 112222,\n                           112176, 112202, 112191, 112206, 112202, 112240, 112197, 112204, 112197,\n                           112204, 112180, 112175, 112179, 112181, 112188, 112181, 112197, 112206,\n                           112203, 112206, 112206, 112240, 112193, 112193, 112193, 112193, 112193,\n                           112182, 112184, 112195, 112180, 112193, 112193, 112193, 112226, 112193,\n                           112208, 112208, 112193, 112226, 112177, 112185, 112198, 112181, 112191,\n                           112208, 112212, 112226, 112226, 112206, 112224, 112224, 112244, 112246,\n                           112244, 112246, 112180, 112210, 112193, 112193, 112193, 112226, 112184,\n                           112209, 112216, 112193, 112193, 112193, 112196, 112201, 112201, 112174,\n                           112175, 112191, 112212, 112193, 112195, 112208, 112207, 112208, 112215,\n                           112190, 112203, 112218, 112218, 112186, 112187, 112217, 112224, 112232,\n                           112233, 112226, 112195, 112188, 112226, 112209, 112243, 112246, 112241,\n                           112243, 112244, 112210, 112175, 112200, 112218, 112224, 112247, 112175,\n                           112190, 112193, 112201, 112180, 112193, 112180, 112206, 112177, 112209,\n                           112192, 112185, 112195, 112180, 112189, 112194, 112248, 112211, 112240,\n                           112211, 112244, 112192, 112217, 112195, 112209, 112216, 112209, 112184,\n                           112197, 112185, 112243, 112246, 112177, 112181, 112198, 112185, 112195,\n                           112232, 112178, 112217, 112198, 112193, 112191, 112203, 112218, 112239,\n                           112204, 112175, 112179, 112247, 112203, 112218, 112239, 112208, 112212,\n                           112234, 112182, 112184, 112201, 112199, 112197, 112224, 112199, 112219,\n                           112181, 112243, 112244, 112201, 112211, 112197, 112246, 112180, 112193,\n                           112196, 112201, 112248, 112209, 112195, 112243, 112195, 112195, 112208,\n                           112241, 112202, 112243, 112249, 112250, 112188, 112247, 112176, 112176,\n                           112247, 112200, 112226, 112212, 112218, 112224, 112243, 112217, 112176,\n                           112243, 112244, 112243, 112244, 112179, 112206, 112195, 112189, 112223,\n                           112208, 112227, 112207, 112243, 112244, 112181, 112180, 112211, 112246,\n                           112182, 112193, 112179, 112190, 112180, 112176, 112204, 112211, 112211,\n                           112176, 112227, 112176, 112181, 112190, 112201, 112204, 112211, 112193,\n                           112193, 112193, 112176, 112195, 112176, 112195, 112189, 112213, 112177,\n                           112202, 112212, 112202, 112212, 112203, 112189, 112207, 112207, 112207,\n                           112213, 112214, 112214, 112189, 112231, 112197, 112227, 112199, 112176,\n                           112221, 112240, 112218, 112251, 112206, 112193, 112203, 112206, 112243,\n                           112244, 112176, 112206, 112178, 112222, 112224, 112224, 112201, 112243,\n                           112189, 112193, 112206, 112239, 112218, 112185, 112228, 112229, 112176,\n                           112195, 112193, 112188, 112196, 112176, 112244, 112218, 112220, 112195,\n                           112193, 112207, 112185, 112193, 112184, 112197, 112175, 112175, 112178,\n                           112188, 112224, 112199, 112184, 112175, 112179, 112211, 112193, 112220,\n                           112199, 112193, 112205, 112193, 112186, 112189, 112176, 112206, 112206,\n                           112218, 112206, 112218, 112195, 112201, 112187, 112199, 112180, 112193,\n                           112213, 112208, 112189, 112189, 112211, 112242, 112197, 112193, 112176,\n                           112246, 112219, 112201, 112175, 112197, 112180, 112192, 112195, 112223,\n                           112200, 112243, 112191, 112245, 112245, 112212, 112193, 112184, 112215,\n                           112179, 112207, 112206, 112226, 112221, 112211, 112192, 112224, 112209,\n                           112216, 112234, 112184, 112197, 112208, 112217, 112225, 112224, 112243,\n                           112197, 112181, 112181, 112214, 112182, 112184, 112189, 112222, 112217,\n                           112217, 112180, 112246, 112193, 112214, 112231, 112196]),\n             size=(112252, 112252), nnz=556, density=0.00%)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data_path = '/kaggle/input/d/vuthanhphong/kg-final/kg_final.txt' # Data path\ndf = pd.read_csv(data_path, sep=\" \", header=None, names=['h', 'r', 't'])\ndf = df[df['h'].isin(exploded_df['feature'].unique())] # Filter valid course exists in course - field relastionships.\nother_mapping = {other: idx for idx, other in enumerate(df['t'].unique())}\ndf['t'] = df['t'].map(other_mapping)\n\n# Prepare course - field edge index\ncourse_col = torch.tensor(df['h'].values, dtype=torch.int64)\nother_col = torch.tensor(df['t'].values, dtype=torch.int64)\nother_edge_type = torch.tensor(df['r'].values, dtype=torch.int64) + 2\ncourse_other_edge_index = torch.stack([course_col, other_col], dim=0) # Create course - field edge index\nnum_others = len(other_mapping)\n\ncourse_other_sparse_edge_index = SparseTensor(\n    col = other_col + num_users + num_courses,\n    row = course_col + num_users,\n    sparse_sizes=(num_users + num_courses + num_others, num_users + num_courses + num_others)\n)\n\nprint(course_other_sparse_edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:11:46.477487Z","iopub.execute_input":"2024-12-04T14:11:46.477809Z","iopub.status.idle":"2024-12-04T14:11:46.540246Z","shell.execute_reply.started":"2024-12-04T14:11:46.477783Z","shell.execute_reply":"2024-12-04T14:11:46.539415Z"}},"outputs":[{"name":"stdout","text":"SparseTensor(row=tensor([ 99970,  99970,  99971,  ..., 102795, 102795, 102796]),\n             col=tensor([103207, 106885, 102821,  ..., 103236, 107473, 103124]),\n             size=(110265, 110265), nnz=68772, density=0.00%)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"concat_row = torch.cat([train_sparse_edge_index.storage.row(), train_sparse_edge_index.storage.col(), course_other_sparse_edge_index.storage.row()], dim=0)\nconcat_col = torch.cat([train_sparse_edge_index.storage.col(), train_sparse_edge_index.storage.row(), course_other_sparse_edge_index.storage.col()], dim=0)\n\nedge_type = torch.cat([torch.zeros_like(train_sparse_edge_index.storage.row()), torch.ones_like(train_sparse_edge_index.storage.col()), other_edge_type], dim=0)\n\nnum_nodes = max(concat_row.max().item(), concat_col.max().item()) + 1\nconcatenated_sparse_edge_index = SparseTensor(\n    row=concat_row,\n    col=concat_col,\n    sparse_sizes=(num_nodes, num_nodes)\n)\n\nprint(concatenated_sparse_edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:11:46.542687Z","iopub.execute_input":"2024-12-04T14:11:46.543430Z","iopub.status.idle":"2024-12-04T14:11:46.896059Z","shell.execute_reply.started":"2024-12-04T14:11:46.543388Z","shell.execute_reply":"2024-12-04T14:11:46.894833Z"}},"outputs":[{"name":"stdout","text":"SparseTensor(row=tensor([     0,      0,      0,  ..., 102795, 102796, 102796]),\n             col=tensor([ 99970,  99971,  99972,  ..., 107473,  96170, 103124]),\n             size=(110265, 110265), nnz=3661672, density=0.03%)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch_geometric.nn import GATv2Conv\n\nclass HeteroGATModel(nn.Module):\n    def __init__(self, in_dim = 64, hidden_dim = 32, out_dim = 16, num_layers = 3, heads=2, dropout=0.3):\n        super(HeteroGATModel, self).__init__()\n\n        # Define embeddings for each type of node\n        self.user_entities_embeddings = nn.Embedding(num_users + num_courses + num_others, in_dim)\n        self.gat_layers = nn.ModuleList()\n\n        self.gat_layers.append(GATv2Conv(in_dim, hidden_dim, heads=heads, dropout=dropout, add_self_loops=False))\n        for _ in range(num_layers - 2):\n            self.gat_layers.append(GATv2Conv(hidden_dim * heads, hidden_dim, heads=heads, dropout=dropout, add_self_loops=False))\n        self.gat_layers.append(GATv2Conv(hidden_dim * heads, out_dim, heads=1, concat=False, dropout=dropout, add_self_loops=False))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        # Initialize embeddings\n        nn.init.xavier_uniform_(self.user_entities_embeddings.weight)\n\n        for gat_layer in self.gat_layers:\n            gat_layer.reset_parameters()\n\n    def forward(self, edge_index):\n        x_initial = self.user_entities_embeddings.weight\n        x = x_initial.clone()  # Clone để giữ nguyên embedding ban đầu\n\n        for gat_layer in self.gat_layers[:-1]:\n            x = F.elu(gat_layer(x, edge_index))\n\n        x = self.gat_layers[-1](x, edge_index)\n\n        user_emb_final, course_emb_final, other_emb_final = torch.split(x, [num_users, num_courses, num_others], dim=0)\n        user_emb_initial, course_emb_initial, _  = torch.split(x_initial, [num_users, num_courses, num_others], dim=0)\n        \n        return user_emb_final, user_emb_initial, course_emb_final, course_emb_initial, other_emb_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:11:46.896903Z","iopub.execute_input":"2024-12-04T14:11:46.897168Z","iopub.status.idle":"2024-12-04T14:11:46.908798Z","shell.execute_reply.started":"2024-12-04T14:11:46.897143Z","shell.execute_reply":"2024-12-04T14:11:46.907927Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def RecallPrecision_at_K(groundTruth, r, k):\n    num_correct_pred = torch.sum(r, dim=-1)\n    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n    recall = torch.mean(num_correct_pred / user_num_liked)\n    precision = torch.mean(num_correct_pred) / k\n    \n    return recall.item(), precision.item()\n\ndef NDCG_at_K(groundTruth, r, k):\n    assert len(r) == len(groundTruth)\n    test_matrix = torch.zeros((len(r), k))\n    for i, items in enumerate(groundTruth):\n        length = min(len(items), k)\n        test_matrix[i, :length] = 1\n    max_r = test_matrix\n    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n    dcg = torch.sum(dcg, axis=1)\n    idcg[idcg == 0.] = 1.\n    ndcg = dcg / idcg\n    ndcg[torch.isnan(ndcg)] = 0.\n    #\n    return torch.mean(ndcg).item()\n\ndef get_user_positive_items(edge_index):\n    user_pos_items = {}\n    for i in range(edge_index.shape[1]):\n        user = edge_index[0][i].item()\n        item = edge_index[1][i].item()\n        if user not in user_pos_items:\n            user_pos_items[user] = []\n        user_pos_items[user].append(item)\n        \n    return user_pos_items\n\nfrom torch_geometric.utils import negative_sampling\n\nfrom tqdm import tqdm\n\ndef get_metrics_with_negative_sampling(\n    model, edge_index, sparse_edge_index, exclude_edge_index, train_sparse_edge_index, k, num_neg_samples=100\n):\n    \"\"\"\n    Evaluate the model using explicit negative sampling.\n    \n    Parameters:\n        - model: The trained model.\n        - edge_index: Test edge index (user-item interactions).\n        - sparse_edge_index: Sparse test edge matrix.\n        - exclude_edge_index: Edges to exclude (train + validation).\n        - train_sparse_edge_index: Sparse adjacency matrix for training.\n        - k: Number of top items to evaluate (Recall@K, etc.).\n        - num_neg_samples: Number of negative samples per user.\n    Returns:\n        - recall, precision, ndcg\n    \"\"\"\n    model.eval()\n    # Get user and item embeddings\n    user_embedding, _, item_embedding, _, _ = model.forward(train_sparse_edge_index)\n    user_embedding = user_embedding.cpu().detach().numpy()\n    item_embedding = item_embedding.cpu().detach().numpy()\n    \n    rating = torch.tensor(np.matmul(user_embedding, item_embedding.T))\n\n    # Mask out all positive interactions from train and test data\n    user_pos_items = get_user_positive_items(exclude_edge_index)\n    exclude_users = []\n    exclude_items = []\n    for user, items in user_pos_items.items():\n        exclude_users.extend([user] * len(items))\n        exclude_items.extend(items)\n    rating[exclude_users, exclude_items] = float('-inf')\n\n    # Generate negative samples\n    num_users = rating.shape[0]\n    num_items = rating.shape[1]\n    all_items = torch.arange(num_items)\n    neg_samples = {}\n    for user in range(num_users):\n        pos_items = set(user_pos_items.get(user, []))\n        neg_items = list(set(all_items.tolist()) - pos_items)\n        neg_samples[user] = torch.tensor(neg_items, dtype=torch.long)[\n            torch.randperm(len(neg_items))[:num_neg_samples]\n        ]\n\n    # Evaluate on positive test items + negative samples\n    users = edge_index[0].unique()\n    test_user_pos_items = get_user_positive_items(edge_index)\n    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n    \n    recall = 0.0\n    precision = 0.0\n    ndcg = 0.0\n\n    for user in users:\n        user = user.item()\n        # Combine test positives and sampled negatives\n        test_items = set(test_user_pos_items.get(user, []))\n        sampled_items = list(test_items.union(neg_samples[user].tolist()))\n        \n        # Get top-K recommendations\n        user_ratings = rating[user, sampled_items]\n        _, top_K_items = torch.topk(user_ratings, k=k)\n        top_K_items = [sampled_items[i] for i in top_K_items]\n\n        # Create relevance vector\n        ground_truth_items = set(test_user_pos_items.get(user, []))\n        relevance = torch.tensor(\n            [1.0 if item in ground_truth_items else 0.0 for item in top_K_items]\n        )\n\n        # Calculate metrics\n        recall += torch.sum(relevance) / len(ground_truth_items)\n        precision += torch.sum(relevance) / k\n\n        # Calculate NDCG\n        gains = relevance / torch.log2(torch.arange(2, k + 2).float())\n        dcg = torch.sum(gains)\n        ideal_gains = torch.zeros_like(relevance)\n        ideal_gains[: len(ground_truth_items)] = 1.0\n        idcg = torch.sum(ideal_gains / torch.log2(torch.arange(2, k + 2).float()))\n        ndcg += dcg / idcg\n\n    num_users = len(users)\n    recall /= num_users\n    precision /= num_users\n    ndcg /= num_users\n\n    return recall, precision, ndcg\n\ndef bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_):\n    reg_loss = lambda_ * (users_emb_0.norm(2).pow(2) +\n                          pos_items_emb_0.norm(2).pow(2) +\n                          neg_items_emb_0.norm(2).pow(2)) # L2 loss\n\n    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n    pos_scores = torch.sum(pos_scores, dim=-1)\n    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n    neg_scores = torch.sum(neg_scores, dim=-1)\n    \n    loss = -F.logsigmoid(pos_scores - neg_scores).sum() + reg_loss\n    \n    return loss\n\nimport torch\nimport torch.nn.functional as F\n\ndef custom_negative_sampling(edge_index, num_nodes, num_neg_samples):\n    \"\"\"\n    edge_index: Sparse edge indices of the graph (positive edges)\n    num_nodes: Total number of nodes in the graph\n    num_neg_samples: Number of negative samples per positive sample\n    num_users: Number of user nodes in the graph\n    num_courses: Number of course nodes in the graph\n    \"\"\"\n    # Extract rows and columns from edge_index\n    row, col = edge_index\n    row_device = row.device  # Ensure device compatibility\n\n    # Sample negative nodes outside the user-course range\n    valid_neg_nodes = torch.cat([\n        torch.arange(0, num_users, device=row_device),\n        torch.arange(num_users + num_courses, num_nodes, device=row_device)\n    ])\n    \n    neg_col = valid_neg_nodes[torch.randint(0, valid_neg_nodes.size(0), (row.size(0) * num_neg_samples,))]\n\n    # Ensure negative samples are unique and do not overlap with positive edges\n    mask = torch.isin(neg_col, col)  # Overlap with existing edges\n    while mask.any():\n        neg_col[mask] = valid_neg_nodes[\n            torch.randint(0, valid_neg_nodes.size(0), (mask.sum(),))\n        ]\n        mask = torch.isin(neg_col, col)  # Recheck for overlaps\n\n    # Construct negative edge index\n    neg_edge_index = torch.stack([row.repeat_interleave(num_neg_samples), neg_col]).t()\n\n    return neg_edge_index\n","metadata":{"execution":{"iopub.status.busy":"2024-12-04T14:31:44.415105Z","iopub.execute_input":"2024-12-04T14:31:44.415462Z","iopub.status.idle":"2024-12-04T14:31:44.435934Z","shell.execute_reply.started":"2024-12-04T14:31:44.415430Z","shell.execute_reply":"2024-12-04T14:31:44.435032Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\ntorch.autograd.set_detect_anomaly(True)\nfrom torch.utils.data import DataLoader\nfrom torch_geometric.utils import negative_sampling\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Parameters\nepochs = 20  # Number of epochs\ncheck_step = 2  # Evaluate every `check_step` epochs\nbatch_size = 2048  # Batch size for training\nlambda_ = 0.001  # Regularization parameter\n\n# Initialize the model, optimizer, and other components\nmodel = HeteroGATModel()\nmodel.to(device)  # Move the model to the device (GPU or CPU)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)\n\nfor epoch in range(1, epochs + 1):\n    model.train()\n    trn_loader = DataLoader(train_edge_index.T, batch_size=batch_size, shuffle=True)\n    trn_loss = 0\n\n    # Wrap the DataLoader in tqdm to track batches\n    batch_bar = tqdm(trn_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n    for batch_idx, batch_pos_edges in enumerate(batch_bar):\n        batch_pos_edges = batch_pos_edges.T\n        batch_pos_edges = batch_pos_edges.to(device)  # Move batch to device\n\n        # Forward pass with multiple adjacency matrices\n        user_emb_final, user_emb_initial, course_emb_final, course_emb_initial, other_emb_final = model.forward(\n            concatenated_sparse_edge_index.to(device)\n        )\n\n        # Generate negative samples for the batch\n        batch_neg_edges = negative_sampling(\n            train_edge_index.to(device),  # Ensure train_edge_index is on the same device\n            num_nodes=[num_users, num_courses],\n            num_neg_samples=batch_pos_edges.shape[1],\n        ).to(device)  # Ensure negative samples are on the same device\n\n        # Extract indices for users, positive items, and negative items\n        user_indices = batch_pos_edges[0].to(device)\n        pos_item_indices = batch_pos_edges[1].to(device)\n        neg_item_indices = batch_neg_edges[1].to(device)\n\n        # Embed users and items based on the indices\n        users_emb_final = user_emb_final[user_indices]\n        users_emb_initial = user_emb_initial[user_indices]\n        pos_items_emb_final = course_emb_final[pos_item_indices]\n        neg_items_emb_final = course_emb_final[neg_item_indices]\n        pos_items_emb_initial = course_emb_initial[pos_item_indices]\n        neg_items_emb_initial = course_emb_initial[neg_item_indices]\n\n        # Calculate BPR loss\n        loss = bpr_loss(\n            users_emb_final, \n            users_emb_initial, \n            pos_items_emb_final, \n            pos_items_emb_initial, \n            neg_items_emb_final, \n            neg_items_emb_initial, \n            lambda_\n        )\n            \n        all_emb_final = torch.cat([user_emb_final, course_emb_final, other_emb_final], dim=0)\n        \n        # Move row and column indices to device\n        row_indices = concatenated_sparse_edge_index.storage.row().to(device)\n        col_indices = concatenated_sparse_edge_index.storage.col().to(device)\n    \n        mask = torch.isin(row_indices, batch_pos_edges[1])\n    \n        course_indices = row_indices[mask]\n        other_indices = col_indices[mask]\n    \n        pos_edge_index = torch.stack([course_indices, other_indices], dim=0).to(device)\n    \n        # Negative sampling\n        neg_edge_index= custom_negative_sampling(\n            pos_edge_index, num_users + num_courses + num_others, 1\n        )\n\n        del row_indices\n        del col_indices\n    \n        # Get embeddings for positive and negative samples\n        pos_course_emb = all_emb_final[course_indices].to(device)\n        pos_other_emb = all_emb_final[other_indices].to(device)\n    \n        neg_row_indices = neg_edge_index[:, 0].to(device)\n        neg_col_indices = neg_edge_index[:, 1].to(device)\n    \n        neg_other_emb = all_emb_final[neg_col_indices].to(device)  # Negative samples\n    \n        # Positive and negative scores\n        pos_score = torch.sum(torch.pow(pos_course_emb - pos_other_emb, 2), dim=1)\n        neg_score = torch.sum(torch.pow(pos_course_emb - neg_other_emb, 2), dim=1)\n    \n        # Loss computation\n        kg_loss = F.softplus(pos_score - neg_score)  # Contrastive loss between positive and negative samples\n        kg_loss = torch.mean(kg_loss)  # Mean loss over the batch\n\n        loss += kg_loss * 300\n\n        optimizer.zero_grad()\n        loss.backward(retain_graph=True)\n        optimizer.step()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Optional gradient clipping\n\n        trn_loss += loss.item()\n\n        # Update tqdm with current batch loss\n        batch_bar.set_postfix(batch_loss=loss.item())\n        \n    trn_loss = trn_loss / len(trn_loader)\n    print(f\"Epoch {epoch}/{epochs} - Training loss: {trn_loss:.6f}\")\n\n    # Evaluate and display metrics every `check_step` epochs\n    if epoch != 0 and epoch % check_step == 0:\n        model.eval()\n        recall, precision, ndcg = get_metrics_with_negative_sampling(\n            model, \n            test_edge_index.to(device),  # Ensure test_edge_index is on the same device\n            test_sparse_edge_index.to(device),  # Ensure test_sparse_adj is on the same device\n            train_edge_index.to(device),  # Ensure train_edge_index is on the same device\n            concatenated_sparse_edge_index.to(device),  # Ensure sparse_adjs is on the same device\n            k=10\n        )\n        score = 0.75 * recall + 0.25 * ndcg\n\n        print(f'[{epoch:03d}/{epochs}] | loss: {trn_loss:.6f} | recall@{10}: {recall:.6f} | '\n              f'precision@{10}: {precision:.6f} | ndcg@{10}: {ndcg:.6f} | score: {score:.6f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-12-04T18:11:16.676512Z","iopub.execute_input":"2024-12-04T18:11:16.676929Z","iopub.status.idle":"2024-12-04T22:17:00.769356Z","shell.execute_reply.started":"2024-12-04T18:11:16.676898Z","shell.execute_reply":"2024-12-04T22:17:00.768566Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20 - Training loss: 221.834242\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20 - Training loss: 177.958128\n[002/20] | loss: 177.958128 | recall@10: 0.682635 | precision@10: 0.068307 | ndcg@10: 0.427428 | score: 0.618833\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20 - Training loss: 168.791070\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20 - Training loss: 164.479100\n[004/20] | loss: 164.479100 | recall@10: 0.690167 | precision@10: 0.069061 | ndcg@10: 0.440914 | score: 0.627854\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20 - Training loss: 162.021738\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20 - Training loss: 159.854274\n[006/20] | loss: 159.854274 | recall@10: 0.699370 | precision@10: 0.069982 | ndcg@10: 0.446799 | score: 0.636227\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20 - Training loss: 158.630174\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20 - Training loss: 157.242153\n[008/20] | loss: 157.242153 | recall@10: 0.697139 | precision@10: 0.069758 | ndcg@10: 0.446821 | score: 0.634560\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20 - Training loss: 157.021591\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20 - Training loss: 155.911550\n[010/20] | loss: 155.911550 | recall@10: 0.703181 | precision@10: 0.070363 | ndcg@10: 0.450853 | score: 0.640099\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20 - Training loss: 155.474730\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20 - Training loss: 154.936822\n[012/20] | loss: 154.936822 | recall@10: 0.700190 | precision@10: 0.070064 | ndcg@10: 0.447452 | score: 0.637006\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20 - Training loss: 154.101833\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20 - Training loss: 153.380648\n[014/20] | loss: 153.380648 | recall@10: 0.702101 | precision@10: 0.070255 | ndcg@10: 0.454429 | score: 0.640183\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20 - Training loss: 153.430245\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20 - Training loss: 152.978741\n[016/20] | loss: 152.978741 | recall@10: 0.706742 | precision@10: 0.070720 | ndcg@10: 0.457188 | score: 0.644354\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20 - Training loss: 152.771110\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20 - Training loss: 152.363962\n[018/20] | loss: 152.363962 | recall@10: 0.708553 | precision@10: 0.070901 | ndcg@10: 0.458023 | score: 0.645920\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20 - Training loss: 152.345592\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20:  89%|████████▉ | 1560/1755 [09:48<01:14,  2.62it/s, batch_loss=138]","output_type":"stream"},{"name":"stdout","text":"[020/20] | loss: 151.880473 | recall@10: 0.702361 | precision@10: 0.070281 | ndcg@10: 0.452565 | score: 0.639912\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"checkpoint = {'model': HeteroGATModel(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T16:52:10.578288Z","iopub.execute_input":"2024-12-04T16:52:10.578681Z","iopub.status.idle":"2024-12-04T16:52:10.831665Z","shell.execute_reply.started":"2024-12-04T16:52:10.578647Z","shell.execute_reply":"2024-12-04T16:52:10.830836Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def recommend_courses_for_user(\n    model, user_id, train_sparse_edge_index, exclude_edge_index, top_k=10\n):\n    \"\"\"\n    Recommend courses for a given user ID.\n    \n    Parameters:\n        - model: The trained recommendation model.\n        - user_id: The user ID to generate recommendations for.\n        - train_sparse_edge_index: Sparse adjacency matrix for training.\n        - exclude_edge_index: Edges to exclude (train + validation interactions).\n        - top_k: Number of top items to recommend (default: 10).\n    \n    Returns:\n        - A list of top_k recommended course IDs.\n    \"\"\"\n    model.eval()\n\n    # Get user and item embeddings\n    user_embedding, _, item_embedding, _, _ = model.forward(train_sparse_edge_index)\n    user_embedding = user_embedding.cpu().detach().numpy()\n    item_embedding = item_embedding.cpu().detach().numpy()\n\n    # Compute scores for all items for the given user\n    user_vector = user_embedding[user_id]\n    scores = np.dot(user_vector, item_embedding.T)\n\n    # Mask out already interacted items\n    user_pos_items = get_user_positive_items(exclude_edge_index)\n    exclude_items = set(user_pos_items.get(user_id, []))\n    scores[list(exclude_items)] = float('-inf')  # Set scores for interacted items to -inf\n\n    # Get the top-K items\n    top_k_items = np.argsort(-scores)[:top_k]  # Sort in descending order and pick top K\n\n    return top_k_items\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T16:56:23.915107Z","iopub.execute_input":"2024-12-04T16:56:23.915801Z","iopub.status.idle":"2024-12-04T16:56:23.922464Z","shell.execute_reply.started":"2024-12-04T16:56:23.915765Z","shell.execute_reply":"2024-12-04T16:56:23.921429Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Assume the model is already trained, and data is preprocessed\nuser_id = 123  # Replace with the target user ID\nrecommended_courses = recommend_courses_for_user(\n    model,\n    user_id=user_id,\n    train_sparse_edge_index=concatenated_sparse_edge_index.to(device),\n    exclude_edge_index=torch.cat([train_edge_index, test_edge_index], dim = -1).to(device),\n    top_k=10\n)\n\nprint(f\"Recommended courses for user {user_id}: {recommended_courses}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:01:35.834388Z","iopub.execute_input":"2024-12-04T17:01:35.834773Z","iopub.status.idle":"2024-12-04T17:02:42.646944Z","shell.execute_reply.started":"2024-12-04T17:01:35.834741Z","shell.execute_reply":"2024-12-04T17:02:42.645891Z"}},"outputs":[{"name":"stdout","text":"Recommended courses for user 123: [1956 2572 1966 2645 1648 1954 2685 2543 2330  497]\n","output_type":"stream"}],"execution_count":31}]}